{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from pprint import pprint\n",
    "\n",
    "config = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"database\": \"senior_design\"\n",
    "}\n",
    "connection = mysql.connector.connect(**config)\n",
    "cursor = connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-06b8ee63bc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT distinct asin, COUNT(asin) AS count FROM review GROUP BY asin ORDER BY count DESC\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0masins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0masin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0masins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W0212\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mServerCmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36m_send_cmd\u001b[0;34m(self, command, argument, packet_number, packet, expect_response, compressed_packet_number)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpect_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend_empty_packet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/network.py\u001b[0m in \u001b[0;36mrecv_plain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mpacket_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mpacket_len\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpacket_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2013\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = \"SELECT distinct asin, COUNT(asin) AS count FROM review GROUP BY asin ORDER BY count DESC\"\n",
    "cursor.execute(query)\n",
    "asins = []\n",
    "for asin, count in cursor:\n",
    "    asins.append((asin,count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(asins[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reviews(asin):\n",
    "    query = \"SELECT review_text FROM review WHERE asin = '{}'\".format(asin)\n",
    "    cursor.execute(query)\n",
    "    reviews = []\n",
    "    for (review_text) in cursor:\n",
    "        reviews.append(review_text[0])\n",
    "    print(\"# reviews: {}\".format(len(reviews)))\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# reviews: 99\n"
     ]
    }
   ],
   "source": [
    "reviews = get_all_reviews(\"B002P3F5D2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lexicon = {\"good\", \"great\", \"better\", \"excellent\", \"best\", \"easy\", \"nice\", \"simple\", \"clear\", \"strong\", \n",
    "                    \"perfect\", \"comfortable\", \"friendly\", \"solid\", \"precise\", \"awesome\", \"amazing\", \"bright\", \"vibrant\",\n",
    "                    \"fantastic\", \"vibrant\", \"realistic\", \"stunning\", \"superior\", \"super\", \"rich\", \"exceptional\",\n",
    "                    \"impressive\", \"ideal\"}\n",
    "negative_lexicon = {\"poor\", \"old\", \"bad\", \"weak\", \"annoying\", \"defective\", \"horrible\", \"buggy\", \"worst\", \"mediocre\",\n",
    "                    \"difficult\", \"unstable\", \"inferior\", \"lousy\", \"complicated\", \"useless\", \"unreliable\", \"sloppy\",\n",
    "                    \"strange\", \"weird\", \"malfunctioning\", \"miserable\", \"terrible\", \"misleading\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "# Start the CoreNLP server with:\n",
    "# java -mx4g -cp \"./CoreNLP/*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "#     (on my Mac, java8 bin located at /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java)\n",
    "nlp = CoreNLPDependencyParser(url=\"http://localhost:9000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# input: parsed_sentence, cumulative information dictionaries (FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count)\n",
    "# output: extracted dependency features\n",
    "def extract_relevant_dependencies(parsed_sentence, FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count):\n",
    "    extracted_sentence = []\n",
    "    for (gov, gov_pos), dependency, (dep, dep_pos) in parsed_sentence.triples():\n",
    "        if not gov.isalpha() or not dep.isalpha():\n",
    "            continue\n",
    "        gov = gov.lower()\n",
    "        dep = dep.lower()\n",
    "        if dependency == \"nsubj\" and dep_pos == \"NN\":\n",
    "            OF_dict[gov] = dep\n",
    "            FO_dict[dep] = gov\n",
    "            features_count[dep] += 1\n",
    "            opinions_count[gov] += 1\n",
    "        elif dependency == \"amod\" and gov_pos == \"NN\":\n",
    "            OF_dict[dep] = gov\n",
    "            FO_dict[gov] = dep\n",
    "            opinions_count[dep] += 1\n",
    "            features_count[gov] += 1\n",
    "        elif dependency == \"conj\":\n",
    "            if gov_pos == \"JJ\" and dep_pos == \"JJ\":\n",
    "                OO_dict[gov].append(dep)\n",
    "                OO_dict[dep].append(gov)\n",
    "                opinions_count[gov] += 1\n",
    "                opinions_count[dep] += 1\n",
    "            elif gov_pos == \"NN\" and dep_pos == \"NN\":\n",
    "                FF_dict[gov].append(dep)\n",
    "                FF_dict[dep].append(gov)\n",
    "                features_count[gov] += 1\n",
    "                features_count[dep] += 1\n",
    "        extracted_sentence.append(((gov, gov_pos), dependency, (dep, dep_pos)))\n",
    "    #parsed_sentences.append(extracted_sentence)\n",
    "    return extracted_sentence\n",
    "\n",
    "\n",
    "# input: all_review_info, cumulative information dictionaries\n",
    "# output: new_features, new_opinions\n",
    "def double_propagation_iterate(all_review_info,\n",
    "                               features,\n",
    "                               feature_words_by_review,\n",
    "                               feature_sentiments_by_review,\n",
    "                               feature_sentiments_cumulative,\n",
    "                               feature_sentiments_pos,\n",
    "                               feature_sentiments_neg,\n",
    "                               opinions,\n",
    "                               opinion_words_by_review,\n",
    "                               opinion_sentiments):\n",
    "    new_opinions = set()\n",
    "    new_features = set()\n",
    "\n",
    "    for index, info in all_review_info.items():\n",
    "        feature_sentiments_by_review[index] = defaultdict(int)\n",
    "\n",
    "        for opinion, feature in info['OF_dict'].items():\n",
    "            if opinion in opinions:\n",
    "                if feature not in features:\n",
    "                    new_features.add(feature)\n",
    "\n",
    "                if feature not in feature_words_by_review[index]:\n",
    "                    feature_words_by_review[index].add(feature)\n",
    "\n",
    "                    # target takes polarity of modifying opinion word\n",
    "                    feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                    # add to target's cumulative sentiment score\n",
    "                    feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                    if opinion_sentiments[opinion] > 0:\n",
    "                        feature_sentiments_pos[feature].append(info['index'])\n",
    "                    elif opinion_sentiments[opinion] < 0:\n",
    "                        feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "                # have we seen this opinion word in this review?\n",
    "                if opinion not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "        for opinion1, related in info['OO_dict'].items():\n",
    "            if opinion1 in opinions:\n",
    "                for opinion in related:\n",
    "                    if opinion not in opinions:\n",
    "                        new_opinions.add(opinion)\n",
    "                        opinion_sentiments[opinion] = opinion_sentiments[opinion1]\n",
    "\n",
    "                    # have we seen this opinion word in this review?\n",
    "                    if opinion not in opinion_words_by_review[index]:\n",
    "                        opinion_words_by_review[index].add(opinion)\n",
    "                        info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "                # have we seen this opinion word in this review?\n",
    "                if opinion1 not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion1)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion1]\n",
    "\n",
    "        for feature, opinion in info['FO_dict'].items():\n",
    "            if feature in features:\n",
    "                if opinion not in opinions:\n",
    "                    new_opinions.add(opinion)\n",
    "\n",
    "                    # if target has sentiment in current review\n",
    "                    if feature in feature_words_by_review[index]:\n",
    "                        # then opinion takes polarity of target (Homogenous Rule)\n",
    "                        opinion_sentiments[opinion] = feature_sentiments_by_review[index][feature]\n",
    "                    else:\n",
    "                        # else target is from another review\n",
    "                        # opinion takes cumulative sentiment of entire review (Intra-review Rule)\n",
    "                        try:\n",
    "                            cumulative_polarity = int(info['cumulative_polarity'] / abs(info['cumulative_polarity']))\n",
    "                        except ZeroDivisionError:\n",
    "                            cumulative_polarity = 0\n",
    "                        opinion_sentiments[opinion] = cumulative_polarity\n",
    "\n",
    "                        # also apply that polarity to the feature (should we do this?)\n",
    "                        feature_words_by_review[index].add(feature)\n",
    "                        feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                        # add to target's cumulative sentiment\n",
    "                        feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                        if opinion_sentiments[opinion] > 0:\n",
    "                            feature_sentiments_pos[feature].append(info['index'])\n",
    "                        elif opinion_sentiments[opinion] < 0:\n",
    "                            feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "                if opinion not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "                if feature not in feature_sentiments_by_review[index]:\n",
    "                    feature_words_by_review[index].add(feature)\n",
    "                    feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                    # add to target's cumulative sentiment\n",
    "                    feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                    if opinion_sentiments[opinion] > 0:\n",
    "                        feature_sentiments_pos[feature].append(info['index'])\n",
    "                    elif opinion_sentiments[opinion] < 0:\n",
    "                        feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "        for feature1, related in info['FF_dict'].items():\n",
    "            if feature1 in features and feature1 in feature_sentiments_by_review[index]:\n",
    "                for feature in related:\n",
    "                    if feature not in features:\n",
    "                        new_features.add(feature)\n",
    "\n",
    "                    # have we seen this target word in this review?\n",
    "                    if feature not in feature_words_by_review[index]:\n",
    "                        feature_words_by_review[index].add(feature)\n",
    "\n",
    "                        # Homogenous Rule\n",
    "                        feature_sentiments_by_review[index][feature] = feature_sentiments_by_review[index][feature1]\n",
    "                        feature_sentiments_cumulative[feature] += feature_sentiments_by_review[index][feature]\n",
    "                        if feature_sentiments_by_review[index][feature] > 0:\n",
    "                            feature_sentiments_pos[feature].append(info['index'])\n",
    "                        elif feature_sentiments_by_review[index][feature] < 0:\n",
    "                            feature_sentiments_neg[feature].append(info['index'])\n",
    "    return new_features, new_opinions\n",
    "\n",
    "\n",
    "# input: list of review texts\n",
    "# output: all features, expanded opinion lexicon\n",
    "def extract_features_opinions(reviews):\n",
    "    features = set()\n",
    "    features_count = defaultdict(int)\n",
    "    opinions = positive_lexicon.union(negative_lexicon)\n",
    "    opinions_count = defaultdict(int)\n",
    "    \n",
    "    raw_sentences = []\n",
    "    parsed_sentences = []\n",
    "    parses = []\n",
    "    review_indices = []\n",
    "    review_info = {} # store info about deps on per review basis\n",
    "    for i, review in enumerate(reviews):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        OF_dict = {}\n",
    "        FO_dict = {}\n",
    "        OO_dict = defaultdict(list)\n",
    "        FF_dict = defaultdict(list)\n",
    "        \n",
    "        raw_sentences.extend(sent_tokenize(review))\n",
    "        parse = nlp.parse_text(review)\n",
    "        parses.append(parse)\n",
    "        for sentence in parse:\n",
    "            # extract relevant dependency information\n",
    "            extracted_sentence = extract_relevant_dependencies(sentence, FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count)\n",
    "            \n",
    "            review_indices.append(i)\n",
    "            parsed_sentences.append(extracted_sentence)\n",
    "\n",
    "        review_info[i] = { 'index' : i,\n",
    "                           'OF_dict' : OF_dict,\n",
    "                           'FO_dict' : FO_dict,\n",
    "                           'OO_dict' : OO_dict,\n",
    "                           'FF_dict' : FF_dict,\n",
    "                           'cumulative_polarity' : 0 }\n",
    "\n",
    "    # instantiate cumulative data structures\n",
    "    i = 0\n",
    "    feature_sentiments_by_review = defaultdict(dict) # same sentiment for target words within review (this is an assumption [Observation 1])\n",
    "    feature_sentiments_cumulative = defaultdict(int)\n",
    "    feature_sentiments_pos = defaultdict(list) # keep track of the review indices that contributed negative sentiments toward each feature\n",
    "    feature_sentiments_neg = defaultdict(list) # keep track of the review indices that contributed negative sentiments toward each feature\n",
    "    feature_words_by_review = defaultdict(set) # keep track of the feature words in each review\n",
    "    opinion_words_by_review = defaultdict(set) # keep track of the opinion words in each review\n",
    "    opinion_sentiments = {} # same sentiment for opinion words throughout the corpus (this is an assumption [Observation 2])\n",
    "    opinion_sentiments.update({op:(1 if op in positive_lexicon else -1) for op in opinions})\n",
    "\n",
    "    while (True):\n",
    "        print(\"DP Iteration: {}\".format(i))\n",
    "        i += 1\n",
    "\n",
    "        # double propagation step\n",
    "        new_features, \\\n",
    "        new_opinions = double_propagation_iterate(review_info,\n",
    "                                                  features,\n",
    "                                                  feature_words_by_review,\n",
    "                                                  feature_sentiments_by_review,\n",
    "                                                  feature_sentiments_cumulative,\n",
    "                                                  feature_sentiments_pos,\n",
    "                                                  feature_sentiments_neg,\n",
    "                                                  opinions,\n",
    "                                                  opinion_words_by_review,\n",
    "                                                  opinion_sentiments)\n",
    "        \n",
    "        features = features.union(new_features)\n",
    "        opinions = opinions.union(new_opinions)\n",
    "        if len(new_opinions) == 0 and len(new_features) == 0:\n",
    "            break\n",
    "\n",
    "    res = (features,\n",
    "           features_count,\n",
    "           opinions,\n",
    "           opinions_count,\n",
    "           raw_sentences,\n",
    "           parsed_sentences,\n",
    "           review_indices,\n",
    "           feature_sentiments_by_review,\n",
    "           feature_words_by_review,\n",
    "           feature_sentiments_cumulative,\n",
    "           feature_sentiments_pos,\n",
    "           feature_sentiments_neg,\n",
    "           opinion_words_by_review,\n",
    "           opinion_sentiments)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product quality clustering\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "feature_to_class = pickle.load(open(\"./clustering/results/clean-classes.pkl\", \"rb\"))\n",
    "\n",
    "def get_sorted_classes(features_by_count):\n",
    "    frequent_features = [(f, cnt) for f, cnt in features_by_count if cnt >= 5]\n",
    "    features_by_class = dict()\n",
    "    not_found = set()\n",
    "\n",
    "    # features_by_class is a dict from class number -> [feature list, total count]\n",
    "    for feature, cnt in frequent_features:\n",
    "        if feature not in feature_to_class:\n",
    "            not_found.add(feature)\n",
    "            continue\n",
    "        class_num = feature_to_class[feature]\n",
    "        if class_num not in features_by_class:\n",
    "            features_by_class[class_num] = [[], 0]\n",
    "        features_by_class[class_num][0].append(feature)\n",
    "        features_by_class[class_num][1] += cnt\n",
    "\n",
    "    sorted_classes = sorted(features_by_class.values(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Not found in any cluster: \" + str(not_found))\n",
    "    return sorted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "DP Iteration: 0\n",
      "DP Iteration: 1\n",
      "DP Iteration: 2\n",
      "DP Iteration: 3\n",
      "DP Iteration: 4\n",
      "DP Iteration: 5\n",
      "DP Iteration: 6\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "features, \\\n",
    "features_count, \\\n",
    "opinions, \\\n",
    "opinions_count, \\\n",
    "raw_sentences, \\\n",
    "parsed_sentences, \\\n",
    "review_indices, \\\n",
    "feature_sentiments_by_review, \\\n",
    "feature_words_by_review, \\\n",
    "feature_sentiments_cumulative, \\\n",
    "feature_sentiments_pos, \\\n",
    "feature_sentiments_neg, \\\n",
    "opinion_words_by_review, \\\n",
    "opinion_sentiments = extract_features_opinions(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature words, occurrences:\n",
      "[('camera', 83),\n",
      " ('quality', 66),\n",
      " ('camcorder', 51),\n",
      " ('video', 36),\n",
      " ('battery', 27),\n",
      " ('product', 18),\n",
      " ('sound', 18),\n",
      " ('software', 18),\n",
      " ('size', 17),\n",
      " ('lens', 17),\n",
      " ('thing', 15),\n",
      " ('problem', 15),\n",
      " ('button', 14),\n",
      " ('time', 13),\n",
      " ('picture', 12),\n",
      " ('input', 11),\n",
      " ('light', 11),\n",
      " ('something', 10),\n",
      " ('option', 9),\n",
      " ('tripod', 9),\n",
      " ('audio', 9),\n",
      " ('ease', 9),\n",
      " ('computer', 8),\n",
      " ('microphone', 8),\n",
      " ('unit', 8),\n",
      " ('support', 8),\n",
      " ('cable', 8),\n",
      " ('hd', 7),\n",
      " ('jack', 7),\n",
      " ('card', 7),\n",
      " ('drive', 7),\n",
      " ('cord', 7),\n",
      " ('price', 6),\n",
      " ('connector', 6),\n",
      " ('memory', 6),\n",
      " ('color', 6),\n",
      " ('generation', 6),\n",
      " ('design', 6),\n",
      " ('one', 6),\n",
      " ('port', 6),\n",
      " ('model', 6),\n",
      " ('capture', 6),\n",
      " ('flip', 5),\n",
      " ('point', 5),\n",
      " ('charger', 5),\n",
      " ('way', 5),\n",
      " ('finish', 5),\n",
      " ('screen', 5),\n",
      " ('operation', 5),\n",
      " ('device', 5),\n",
      " ('image', 5),\n",
      " ('review', 5),\n",
      " ('difference', 5),\n",
      " ('hand', 4),\n",
      " ('user', 4),\n",
      " ('complaint', 4),\n",
      " ('solution', 4),\n",
      " ('drawback', 4),\n",
      " ('buy', 4),\n",
      " ('use', 4),\n",
      " ('purchase', 4),\n",
      " ('gadget', 4),\n",
      " ('sensitivity', 4),\n",
      " ('feel', 4),\n",
      " ('resolution', 4),\n",
      " ('balance', 4),\n",
      " ('recording', 4),\n",
      " ('level', 4),\n",
      " ('fun', 4),\n",
      " ('fact', 4),\n",
      " ('cam', 4),\n",
      " ('life', 4),\n",
      " ('tap', 4),\n",
      " ('brand', 3),\n",
      " ('mode', 3),\n",
      " ('instruction', 3),\n",
      " ('tv', 3),\n",
      " ('recommendation', 3),\n",
      " ('issue', 3),\n",
      " ('info', 3),\n",
      " ('year', 3),\n",
      " ('plug', 3),\n",
      " ('slot', 3),\n",
      " ('gb', 3),\n",
      " ('purse', 3),\n",
      " ('display', 3),\n",
      " ('guy', 3),\n",
      " ('youtube', 3),\n",
      " ('codec', 3),\n",
      " ('arm', 3),\n",
      " ('research', 3),\n",
      " ('week', 3),\n",
      " ('zoom', 3),\n",
      " ('exposure', 3),\n",
      " ('side', 3),\n",
      " ('connection', 3),\n",
      " ('system', 3),\n",
      " ('nothing', 3),\n",
      " ('case', 3),\n",
      " ('facebook', 3),\n",
      " ('value', 3),\n",
      " ('trip', 3),\n",
      " ('surface', 3),\n",
      " ('setting', 3),\n",
      " ('cost', 3),\n",
      " ('portability', 3),\n",
      " ('function', 3),\n",
      " ('inch', 3),\n",
      " ('charge', 3),\n",
      " ('ability', 3),\n",
      " ('lighting', 3),\n",
      " ('tail', 3),\n",
      " ('def', 3),\n",
      " ('capability', 3),\n",
      " ('provision', 3),\n",
      " ('storage', 3),\n",
      " ('hour', 2),\n",
      " ('date', 2),\n",
      " ('feedback', 2),\n",
      " ('lense', 2),\n",
      " ('phone', 2),\n",
      " ('space', 2),\n",
      " ('buttonsrecord', 2),\n",
      " ('upload', 2),\n",
      " ('dvd', 2),\n",
      " ('feature', 2),\n",
      " ('verdict', 2),\n",
      " ('sennheiser', 2),\n",
      " ('range', 2),\n",
      " ('disappointment', 2),\n",
      " ('waste', 2),\n",
      " ('service', 2),\n",
      " ('part', 2),\n",
      " ('husband', 2),\n",
      " ('definition', 2),\n",
      " ('stabilization', 2),\n",
      " ('lot', 2),\n",
      " ('weight', 2),\n",
      " ('playback', 2),\n",
      " ('field', 2),\n",
      " ('everything', 2),\n",
      " ('end', 2),\n",
      " ('span', 2),\n",
      " ('switch', 2),\n",
      " ('friend', 2),\n",
      " ('performance', 2),\n",
      " ('tool', 2),\n",
      " ('fidelity', 2),\n",
      " ('method', 2),\n",
      " ('file', 2),\n",
      " ('aac', 2),\n",
      " ('room', 2),\n",
      " ('state', 2),\n",
      " ('wife', 2),\n",
      " ('highly', 2),\n",
      " ('anyone', 2),\n",
      " ('weather', 2),\n",
      " ('strap', 2),\n",
      " ('criticism', 2),\n",
      " ('category', 2),\n",
      " ('footage', 2),\n",
      " ('interface', 2),\n",
      " ('pouch', 2),\n",
      " ('spot', 2),\n",
      " ('bit', 2),\n",
      " ('novice', 2),\n",
      " ('company', 2),\n",
      " ('comparison', 2),\n",
      " ('pc', 2),\n",
      " ('appearance', 2),\n",
      " ('power', 2),\n",
      " ('confirmation', 2),\n",
      " ('gripe', 2),\n",
      " ('deal', 2),\n",
      " ('towel', 2),\n",
      " ('colar', 2),\n",
      " ('sweatshirt', 2),\n",
      " ('blue', 2),\n",
      " ('disc', 2),\n",
      " ('purpose', 2),\n",
      " ('convenience', 2),\n",
      " ('twitter', 2),\n",
      " ('client', 2),\n",
      " ('nail', 2),\n",
      " ('base', 2),\n",
      " ('zi', 2),\n",
      " ('control', 2),\n",
      " ('flipcam', 1),\n",
      " ('half', 1),\n",
      " ('day', 1),\n",
      " ('vendor', 1),\n",
      " ('manual', 1),\n",
      " ('up', 1),\n",
      " ('construction', 1),\n",
      " ('place', 1),\n",
      " ('bang', 1),\n",
      " ('face', 1),\n",
      " ('sale', 1),\n",
      " ('palm', 1),\n",
      " ('pocket', 1),\n",
      " ('television', 1),\n",
      " ('action', 1),\n",
      " ('mine', 1),\n",
      " ('ton', 1),\n",
      " ('pad', 1),\n",
      " ('effect', 1),\n",
      " ('taking', 1),\n",
      " ('recorder', 1),\n",
      " ('investment', 1),\n",
      " ('afternoon', 1),\n",
      " ('flow', 1),\n",
      " ('result', 1),\n",
      " ('headache', 1),\n",
      " ('bike', 1),\n",
      " ('maker', 1),\n",
      " ('nightmare', 1),\n",
      " ('firmware', 1),\n",
      " ('sensor', 1),\n",
      " ('daughter', 1),\n",
      " ('labaryth', 1),\n",
      " ('number', 1),\n",
      " ('registration', 1),\n",
      " ('waranty', 1),\n",
      " ('dad', 1),\n",
      " ('shipping', 1),\n",
      " ('director', 1),\n",
      " ('window', 1),\n",
      " ('step', 1),\n",
      " ('addition', 1),\n",
      " ('lcd', 1),\n",
      " ('mind', 1),\n",
      " ('surprise', 1),\n",
      " ('refund', 1),\n",
      " ('direction', 1),\n",
      " ('daylight', 1),\n",
      " ('cycle', 1),\n",
      " ('version', 1),\n",
      " ('store', 1),\n",
      " ('retail', 1),\n",
      " ('love', 1),\n",
      " ('setup', 1),\n",
      " ('job', 1),\n",
      " ('luck', 1),\n",
      " ('front', 1),\n",
      " ('somebody', 1),\n",
      " ('focus', 1),\n",
      " ('practice', 1),\n",
      " ('bag', 1),\n",
      " ('sign', 1),\n",
      " ('orientation', 1),\n",
      " ('mess', 1),\n",
      " ('salad', 1),\n",
      " ('course', 1),\n",
      " ('shot', 1),\n",
      " ('lowlight', 1),\n",
      " ('son', 1),\n",
      " ('heaven', 1),\n",
      " ('magnification', 1),\n",
      " ('fix', 1),\n",
      " ('equipment', 1),\n",
      " ('pack', 1),\n",
      " ('auto', 1),\n",
      " ('program', 1),\n",
      " ('mother', 1),\n",
      " ('viewfinder', 1),\n",
      " ('sunlight', 1),\n",
      " ('right', 1),\n",
      " ('editing', 1),\n",
      " ('handicam', 1),\n",
      " ('door', 1),\n",
      " ('anything', 1),\n",
      " ('rubber', 1),\n",
      " ('adapter', 1),\n",
      " ('gift', 1),\n",
      " ('adage', 1),\n",
      " ('casing', 1),\n",
      " ('stabilizer', 1),\n",
      " ('snow', 1),\n",
      " ('snowstorm', 1),\n",
      " ('purchaser', 1),\n",
      " ('dslr', 1),\n",
      " ('sd', 1),\n",
      " ('word', 1),\n",
      " ('modeland', 1),\n",
      " ('vacation', 1),\n",
      " ('factor', 1),\n",
      " ('shore', 1),\n",
      " ('means', 1),\n",
      " ('owner', 1),\n",
      " ('tag', 1),\n",
      " ('lightease', 1),\n",
      " ('grip', 1),\n",
      " ('choice', 1),\n",
      " ('wish', 1),\n",
      " ('symbol', 1),\n",
      " ('lesson', 1),\n",
      " ('angle', 1),\n",
      " ('technology', 1),\n",
      " ('packaging', 1),\n",
      " ('look', 1),\n",
      " ('guide', 1),\n",
      " ('qualityi', 1),\n",
      " ('hdtv', 1),\n",
      " ('meaning', 1),\n",
      " ('usability', 1),\n",
      " ('environment', 1),\n",
      " ('package', 1),\n",
      " ('ca', 1),\n",
      " ('online', 1),\n",
      " ('try', 1),\n",
      " ('downside', 1),\n",
      " ('neat', 1),\n",
      " ('child', 1),\n",
      " ('damage', 1),\n",
      " ('vado', 1),\n",
      " ('month', 1),\n",
      " ('kid', 1),\n",
      " ('record', 1),\n",
      " ('while', 1),\n",
      " ('accuracy', 1),\n",
      " ('clip', 1),\n",
      " ('toy', 1),\n",
      " ('error', 1),\n",
      " ('skin', 1),\n",
      " ('red', 1),\n",
      " ('winner', 1),\n",
      " ('gimmick', 1),\n",
      " ('dog', 1),\n",
      " ('bone', 1),\n",
      " ('mac', 1),\n",
      " ('manner', 1),\n",
      " ('type', 1),\n",
      " ('desktop', 1),\n",
      " ('laptop', 1),\n",
      " ('tape', 1),\n",
      " ('replacement', 1),\n",
      " ('requirement', 1),\n",
      " ('junk', 1),\n",
      " ('lapel', 1),\n",
      " ('show', 1),\n",
      " ('night', 1),\n",
      " ('shake', 1),\n",
      " ('object', 1),\n",
      " ('period', 1),\n",
      " ('everyone', 1),\n",
      " ('improvement', 1),\n",
      " ('drag', 1),\n",
      " ('drop', 1),\n",
      " ('transfer', 1),\n",
      " ('sky', 1),\n",
      " ('sun', 1),\n",
      " ('doubt', 1),\n",
      " ('situation', 1),\n",
      " ('firm', 1),\n",
      " ('condition', 1),\n",
      " ('simplicity', 1),\n",
      " ('perfectionist', 1),\n",
      " ('process', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature words, occurrences:\")\n",
    "features_by_count = sorted(features_count.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(features_by_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature clusters:\n",
      "Not found in any cluster: {'thing', 'problem', 'product', 'difference', 'one', 'review', 'something', 'ease'}\n",
      "[[['camera'], 83],\n",
      " [['quality'], 66],\n",
      " [['camcorder'], 51],\n",
      " [['video'], 36],\n",
      " [['input', 'audio', 'cable'], 28],\n",
      " [['battery'], 27],\n",
      " [['jack', 'connector', 'port'], 19],\n",
      " [['sound'], 18],\n",
      " [['software'], 18],\n",
      " [['size'], 17],\n",
      " [['lens'], 17],\n",
      " [['button'], 14],\n",
      " [['time'], 13],\n",
      " [['card', 'memory'], 13],\n",
      " [['picture'], 12],\n",
      " [['generation', 'model'], 12],\n",
      " [['light'], 11],\n",
      " [['flip', 'way'], 10],\n",
      " [['point', 'image'], 10],\n",
      " [['option'], 9],\n",
      " [['tripod'], 9],\n",
      " [['computer'], 8],\n",
      " [['microphone'], 8],\n",
      " [['unit'], 8],\n",
      " [['support'], 8],\n",
      " [['hd'], 7],\n",
      " [['drive'], 7],\n",
      " [['cord'], 7],\n",
      " [['price'], 6],\n",
      " [['color'], 6],\n",
      " [['design'], 6],\n",
      " [['capture'], 6],\n",
      " [['charger'], 5],\n",
      " [['finish'], 5],\n",
      " [['screen'], 5],\n",
      " [['operation'], 5],\n",
      " [['device'], 5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature clusters:\")\n",
    "sorted_classes = get_sorted_classes(features_by_count)\n",
    "pprint(sorted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion words, occurrences:\n",
      "[('good', 35),\n",
      " ('great', 25),\n",
      " ('usb', 22),\n",
      " ('little', 21),\n",
      " ('external', 19),\n",
      " ('is', 19),\n",
      " ('small', 18),\n",
      " ('better', 15),\n",
      " ('easy', 15),\n",
      " ('nice', 15),\n",
      " ('other', 13),\n",
      " ('only', 12),\n",
      " ('video', 12),\n",
      " ('same', 11),\n",
      " ('more', 11),\n",
      " ('quick', 11),\n",
      " ('first', 11),\n",
      " ('old', 10),\n",
      " ('high', 10),\n",
      " ('low', 9),\n",
      " ('short', 9),\n",
      " ('clear', 9),\n",
      " ('mic', 8),\n",
      " ('sound', 8),\n",
      " ('hard', 8),\n",
      " ('excellent', 7),\n",
      " ('bad', 7),\n",
      " ('sensitive', 7),\n",
      " ('last', 7),\n",
      " ('wide', 7),\n",
      " ('was', 6),\n",
      " ('best', 6),\n",
      " ('full', 6),\n",
      " ('awesome', 6),\n",
      " ('creative', 6),\n",
      " ('digital', 6),\n",
      " ('fine', 6),\n",
      " ('new', 5),\n",
      " ('available', 5),\n",
      " ('poor', 5),\n",
      " ('fantastic', 5),\n",
      " ('handy', 5),\n",
      " ('have', 5),\n",
      " ('seems', 5),\n",
      " ('internal', 5),\n",
      " ('included', 5),\n",
      " ('perfect', 5),\n",
      " ('next', 4),\n",
      " ('extra', 4),\n",
      " ('inexpensive', 4),\n",
      " ('right', 4),\n",
      " ('works', 4),\n",
      " ('impressed', 4),\n",
      " ('removable', 4),\n",
      " ('audio', 4),\n",
      " ('big', 4),\n",
      " ('plus', 3),\n",
      " ('defective', 3),\n",
      " ('recording', 3),\n",
      " ('lightweight', 3),\n",
      " ('entire', 3),\n",
      " ('tiny', 3),\n",
      " ('light', 3),\n",
      " ('acceptable', 3),\n",
      " ('huge', 3),\n",
      " ('work', 3),\n",
      " ('cool', 3),\n",
      " ('professional', 3),\n",
      " ('power', 3),\n",
      " ('turn', 3),\n",
      " ('higher', 3),\n",
      " ('has', 3),\n",
      " ('surprised', 3),\n",
      " ('dedicated', 3),\n",
      " ('similar', 3),\n",
      " ('superb', 3),\n",
      " ('crisp', 3),\n",
      " ('appears', 3),\n",
      " ('sure', 3),\n",
      " ('regular', 2),\n",
      " ('simple', 2),\n",
      " ('superior', 2),\n",
      " ('tactile', 2),\n",
      " ('real', 2),\n",
      " ('portable', 2),\n",
      " ('recommend', 2),\n",
      " ('buy', 2),\n",
      " ('photo', 2),\n",
      " ('complicated', 2),\n",
      " ('sharp', 2),\n",
      " ('decent', 2),\n",
      " ('solid', 2),\n",
      " ('going', 2),\n",
      " ('minor', 2),\n",
      " ('worked', 2),\n",
      " ('absolute', 2),\n",
      " ('favorite', 2),\n",
      " ('does', 2),\n",
      " ('lock', 2),\n",
      " ('additional', 2),\n",
      " ('one', 2),\n",
      " ('goes', 2),\n",
      " ('recorded', 2),\n",
      " ('elaborate', 2),\n",
      " ('biggest', 2),\n",
      " ('ridiculous', 2),\n",
      " ('second', 2),\n",
      " ('whole', 2),\n",
      " ('comes', 2),\n",
      " ('compact', 2),\n",
      " ('central', 2),\n",
      " ('areas', 2),\n",
      " ('recent', 2),\n",
      " ('bright', 2),\n",
      " ('amateur', 2),\n",
      " ('quality', 2),\n",
      " ('close', 2),\n",
      " ('spare', 2),\n",
      " ('pleased', 2),\n",
      " ('improve', 2),\n",
      " ('relative', 2),\n",
      " ('projected', 2),\n",
      " ('newest', 2),\n",
      " ('lasts', 2),\n",
      " ('runs', 2),\n",
      " ('white', 2),\n",
      " ('helpful', 2),\n",
      " ('affordable', 2),\n",
      " ('due', 2),\n",
      " ('wider', 2),\n",
      " ('cheap', 2),\n",
      " ('takes', 2),\n",
      " ('purple', 2),\n",
      " ('practical', 2),\n",
      " ('happy', 2),\n",
      " ('heavy', 2),\n",
      " ('about', 2),\n",
      " ('basic', 2),\n",
      " ('got', 2),\n",
      " ('personal', 2),\n",
      " ('years', 1),\n",
      " ('shoots', 1),\n",
      " ('beats', 1),\n",
      " ('ways', 1),\n",
      " ('increases', 1),\n",
      " ('rechargeable', 1),\n",
      " ('fluctuates', 1),\n",
      " ('charge', 1),\n",
      " ('beautiful', 1),\n",
      " ('run', 1),\n",
      " ('cheapest', 1),\n",
      " ('held', 1),\n",
      " ('ago', 1),\n",
      " ('user', 1),\n",
      " ('supposed', 1),\n",
      " ('common', 1),\n",
      " ('needs', 1),\n",
      " ('writing', 1),\n",
      " ('jumpy', 1),\n",
      " ('test', 1),\n",
      " ('number', 1),\n",
      " ('unsatisfied', 1),\n",
      " ('arrived', 1),\n",
      " ('change', 1),\n",
      " ('stinks', 1),\n",
      " ('super', 1),\n",
      " ('figured', 1),\n",
      " ('newer', 1),\n",
      " ('larger', 1),\n",
      " ('funny', 1),\n",
      " ('following', 1),\n",
      " ('spacious', 1),\n",
      " ('capacitive', 1),\n",
      " ('recognize', 1),\n",
      " ('confused', 1),\n",
      " ('ready', 1),\n",
      " ('accurate', 1),\n",
      " ('hollow', 1),\n",
      " ('intuitive', 1),\n",
      " ('boils', 1),\n",
      " ('finished', 1),\n",
      " ('major', 1),\n",
      " ('mega', 1),\n",
      " ('different', 1),\n",
      " ('feature', 1),\n",
      " ('umpteenth', 1),\n",
      " ('neat', 1),\n",
      " ('shakes', 1),\n",
      " ('magic', 1),\n",
      " ('bundled', 1),\n",
      " ('buttons', 1),\n",
      " ('accumulate', 1),\n",
      " ('update', 1),\n",
      " ('inclined', 1),\n",
      " ('accepts', 1),\n",
      " ('registered', 1),\n",
      " ('serial', 1),\n",
      " ('indicated', 1),\n",
      " ('flip', 1),\n",
      " ('bought', 1),\n",
      " ('free', 1),\n",
      " ('microphone', 1),\n",
      " ('exceptional', 1),\n",
      " ('aspiring', 1),\n",
      " ('expired', 1),\n",
      " ('emailed', 1),\n",
      " ('sized', 1),\n",
      " ('playing', 1),\n",
      " ('else', 1),\n",
      " ('occur', 1),\n",
      " ('option', 1),\n",
      " ('broke', 1),\n",
      " ('addition', 1),\n",
      " ('worst', 1),\n",
      " ('button', 1),\n",
      " ('actual', 1),\n",
      " ('wonderful', 1),\n",
      " ('glossy', 1),\n",
      " ('stunning', 1),\n",
      " ('needed', 1),\n",
      " ('lower', 1),\n",
      " ('added', 1),\n",
      " ('surprise', 1),\n",
      " ('way', 1),\n",
      " ('varies', 1),\n",
      " ('selling', 1),\n",
      " ('videoweighs', 1),\n",
      " ('intuitivethe', 1),\n",
      " ('local', 1),\n",
      " ('love', 1),\n",
      " ('cameras', 1),\n",
      " ('difficult', 1),\n",
      " ('mentioned', 1),\n",
      " ('ought', 1),\n",
      " ('upper', 1),\n",
      " ('flush', 1),\n",
      " ('size', 1),\n",
      " ('intrusive', 1),\n",
      " ('troubleshooting', 1),\n",
      " ('correct', 1),\n",
      " ('stayed', 1),\n",
      " ('terrible', 1),\n",
      " ('main', 1),\n",
      " ('teenage', 1),\n",
      " ('overall', 1),\n",
      " ('died', 1),\n",
      " ('fails', 1),\n",
      " ('waste', 1),\n",
      " ('online', 1),\n",
      " ('help', 1),\n",
      " ('lit', 1),\n",
      " ('stay', 1),\n",
      " ('proper', 1),\n",
      " ('convinced', 1),\n",
      " ('bulky', 1),\n",
      " ('outstanding', 1),\n",
      " ('functions', 1),\n",
      " ('hold', 1),\n",
      " ('makes', 1),\n",
      " ('installed', 1),\n",
      " ('prompted', 1),\n",
      " ('do', 1),\n",
      " ('sunlight', 1),\n",
      " ('effective', 1),\n",
      " ('picture', 1),\n",
      " ('deliver', 1),\n",
      " ('sub', 1),\n",
      " ('provide', 1),\n",
      " ('need', 1),\n",
      " ('sony', 1),\n",
      " ('back', 1),\n",
      " ('arm', 1),\n",
      " ('rubber', 1),\n",
      " ('flexible', 1),\n",
      " ('awkward', 1),\n",
      " ('worried', 1),\n",
      " ('outlived', 1),\n",
      " ('horizontal', 1),\n",
      " ('smudged', 1),\n",
      " ('puts', 1),\n",
      " ('sucks', 1),\n",
      " ('such', 1),\n",
      " ('types', 1),\n",
      " ('say', 1),\n",
      " ('alternate', 1),\n",
      " ('replaceable', 1),\n",
      " ('rare', 1),\n",
      " ('operating', 1),\n",
      " ('enough', 1),\n",
      " ('latest', 1),\n",
      " ('lowest', 1),\n",
      " ('accommodate', 1),\n",
      " ('think', 1),\n",
      " ('unlimited', 1),\n",
      " ('obvious', 1),\n",
      " ('highest', 1),\n",
      " ('possible', 1),\n",
      " ('drive', 1),\n",
      " ('settled', 1),\n",
      " ('middle', 1),\n",
      " ('produces', 1),\n",
      " ('astounded', 1),\n",
      " ('highly', 1),\n",
      " ('four', 1),\n",
      " ('charged', 1),\n",
      " ('netbook', 1),\n",
      " ('much', 1),\n",
      " ('amazing', 1),\n",
      " ('factor', 1),\n",
      " ('important', 1),\n",
      " ('inclement', 1),\n",
      " ('appropriate', 1),\n",
      " ('suitable', 1),\n",
      " ('remains', 1),\n",
      " ('reasonable', 1),\n",
      " ('firm', 1),\n",
      " ('sensitivity', 1),\n",
      " ('over', 1),\n",
      " ('prone', 1),\n",
      " ('accompanying', 1),\n",
      " ('informative', 1),\n",
      " ('coolest', 1),\n",
      " ('learned', 1),\n",
      " ('anti', 1),\n",
      " ('unintuitive', 1),\n",
      " ('designed', 1),\n",
      " ('year', 1),\n",
      " ('customary', 1),\n",
      " ('did', 1),\n",
      " ('worth', 1),\n",
      " ('technical', 1),\n",
      " ('genius', 1),\n",
      " ('awful', 1),\n",
      " ('go', 1),\n",
      " ('withstand', 1),\n",
      " ('shooting', 1),\n",
      " ('third', 1),\n",
      " ('allowed', 1),\n",
      " ('agreat', 1),\n",
      " ('slim', 1),\n",
      " ('pops', 1),\n",
      " ('soft', 1),\n",
      " ('able', 1),\n",
      " ('windy', 1),\n",
      " ('outside', 1),\n",
      " ('picked', 1),\n",
      " ('sweet', 1),\n",
      " ('current', 1),\n",
      " ('take', 1),\n",
      " ('fledged', 1),\n",
      " ('choppy', 1),\n",
      " ('complete', 1),\n",
      " ('beat', 1),\n",
      " ('wrong', 1),\n",
      " ('dismayed', 1),\n",
      " ('me', 1),\n",
      " ('suggested', 1),\n",
      " ('underwater', 1),\n",
      " ('tooo', 1),\n",
      " ('use', 1),\n",
      " ('identical', 1),\n",
      " ('inches', 1),\n",
      " ('charging', 1),\n",
      " ('clean', 1),\n",
      " ('left', 1),\n",
      " ('slight', 1),\n",
      " ('brighter', 1),\n",
      " ('physical', 1),\n",
      " ('promotional', 1),\n",
      " ('point', 1),\n",
      " ('make', 1),\n",
      " ('plenty', 1),\n",
      " ('lens', 1),\n",
      " ('narrow', 1),\n",
      " ('red', 1),\n",
      " ('pointed', 1),\n",
      " ('turns', 1),\n",
      " ('indicates', 1),\n",
      " ('pale', 1),\n",
      " ('yellow', 1),\n",
      " ('faded', 1),\n",
      " ('ruby', 1),\n",
      " ('brilliant', 1),\n",
      " ('dark', 1),\n",
      " ('normal', 1),\n",
      " ('gimmick', 1),\n",
      " ('stupid', 1),\n",
      " ('eats', 1),\n",
      " ('chew', 1),\n",
      " ('allow', 1),\n",
      " ('timely', 1),\n",
      " ('look', 1),\n",
      " ('previous', 1),\n",
      " ('outdated', 1),\n",
      " ('desktop', 1),\n",
      " ('match', 1),\n",
      " ('comparable', 1),\n",
      " ('there', 1),\n",
      " ('record', 1),\n",
      " ('elemental', 1),\n",
      " ('sick', 1),\n",
      " ('tired', 1),\n",
      " ('earlier', 1),\n",
      " ('suck', 1),\n",
      " ('secondary', 1),\n",
      " ('suffers', 1),\n",
      " ('ability', 1),\n",
      " ('wireless', 1),\n",
      " ('intended', 1),\n",
      " ('substantial', 1),\n",
      " ('versatile', 1),\n",
      " ('live', 1),\n",
      " ('loud', 1),\n",
      " ('prolonged', 1),\n",
      " ('shiny', 1),\n",
      " ('smudgeable', 1),\n",
      " ('complains', 1),\n",
      " ('special', 1),\n",
      " ('painless', 1),\n",
      " ('integrates', 1),\n",
      " ('easier', 1),\n",
      " ('version', 1),\n",
      " ('rubbery', 1),\n",
      " ('mounts', 1),\n",
      " ('weight', 1),\n",
      " ('preferred', 1),\n",
      " ('prominent', 1),\n",
      " ('smooth', 1),\n",
      " ('automatic', 1),\n",
      " ('blue', 1),\n",
      " ('try', 1),\n",
      " ('long', 1),\n",
      " ('blew', 1),\n",
      " ('surpasses', 1),\n",
      " ('handheld', 1),\n",
      " ('encouraged', 1),\n",
      " ('useless', 1),\n",
      " ('supports', 1),\n",
      " ('camcorder', 1),\n",
      " ('hemorrhaging', 1),\n",
      " ('exited', 1),\n",
      " ('asked', 1),\n",
      " ('knows', 1),\n",
      " ('biting', 1),\n",
      " ('brief', 1),\n",
      " ('forgiving', 1),\n",
      " ('broad', 1),\n",
      " ('multifunction', 1),\n",
      " ('standard', 1),\n",
      " ('mounting', 1),\n",
      " ('flimsyindependent', 1),\n",
      " ('means', 1),\n",
      " ('extrarounded', 1),\n",
      " ('own', 1),\n",
      " ('manual', 1),\n",
      " ('impressive', 1),\n",
      " ('working', 1),\n",
      " ('competent', 1),\n",
      " ('dirty', 1),\n",
      " ('boasted', 1),\n",
      " ('complex', 1),\n",
      " ('bigger', 1),\n",
      " ('true', 1),\n",
      " ('comparative', 1),\n",
      " ('persnickety', 1),\n",
      " ('audiovisual', 1),\n",
      " ('advanced', 1),\n",
      " ('positive', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Opinion words, occurrences:\")\n",
    "opinions_by_count = sorted(opinions_count.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(opinions_by_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def is_sentiment_bearing(adj):\n",
    "    for ss in wn.synsets(adj):\n",
    "        if ss.pos() == \"a\" or ss.pos() == \"s\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT FOUND: {'turn', 'record', 'gimmick', 'camcorder', 'point', 'flimsyindependent', 'option', 'mounting', 'boasted', 'video', 'charging', 'genius', 'stayed', 'supports', 'need', 'suggested', 'did', 'tooo', 'increases', 'beats', 'match', 'functions', 'arm', 'suffers', 'improve', 'sensitivity', 'was', 'added', 'is', 'highly', 'microphone', 'turns', 'test', 'playing', 'update', 'puts', 'unintuitive', 'makes', 'means', 'factor', 'surpasses', 'hold', 'sunlight', 'sucks', 'recording', 'stay', 'try', 'eats', 'sub', 'addition', 'help', 'accommodate', 'suck', 'needs', 'way', 'varies', 'cameras', 'power', 'shooting', 'writing', 'videoweighs', 'exited', 'mega', 'work', 'died', 'has', 'indicates', 'fails', 'smudgeable', 'shoots', 'integrates', 'picked', 'emailed', 'feature', 'intuitivethe', 'takes', 'accepts', 'produces', 'arrived', 'fluctuates', 'do', 'asked', 'user', 'weight', 'drive', 'inches', 'occur', 'boils', 'lasts', 'remains', 'comes', 'me', 'extrarounded', 'areas', 'version', 'say', 'runs', 'recommend', 'allowed', 'does', 'use', 'love', 'picture', 'bought', 'agreat', 'worked', 'works', 'smudged', 'allow', 'lens', 'recognize', 'withstand', 'selling', 'ability', 'prompted', 'buttons', 'make', 'charge', 'year', 'blew', 'mic', 'usb', 'have', 'sony', 'knows', 'audio', 'outlived', 'pops', 'change', 'provide', 'mentioned', 'multifunction', 'buy', 'plenty', 'goes', 'indicated', 'surprise', 'types', 'complains', 'number', 'shakes', 'photo', 'ways', 'there', 'years', 'button', 'desktop', 'seems', 'lock', 'stinks', 'ought', 'deliver', 'else', 'look', 'appears', 'bundled', 'hemorrhaging', 'installed', 'got', 'run', 'think', 'troubleshooting', 'mounts', 'netbook', 'chew', 'take', 'accumulate'}\n",
      "FOUND: {'astounded', 'larger', 'four', 'close', 'next', 'middle', 'spare', 'neat', 'outstanding', 'sized', 'rubber', 'central', 'highest', 'live', 'registered', 'local', 'bigger', 'dedicated', 'accurate', 'overall', 'professional', 'actual', 'teenage', 'learned', 'favorite', 'much', 'acceptable', 'exceptional', 'first', 'firm', 'sound', 'included', 'designed', 'solid', 'narrow', 'surprised', 'secondary', 'second', 'compact', 'prone', 'happy', 'suitable', 'other', 'better', 'wireless', 'preferred', 'awkward', 'crisp', 'basic', 'special', 'intuitive', 'lower', 'sweet', 'ridiculous', 'substantial', 'big', 'simple', 'operating', 'smooth', 'standard', 'super', 'best', 'fledged', 'magic', 'technical', 'yellow', 'aspiring', 'effective', 'pale', 'faded', 'ruby', 'choppy', 'prolonged', 'old', 'portable', 'handheld', 'bright', 'white', 'similar', 'fantastic', 'funny', 'major', 'blue', 'impressive', 'enough', 'practical', 'creative', 'about', 'free', 'unlimited', 'normal', 'regular', 'advanced', 'great', 'flexible', 'elemental', 'flush', 'quick', 'rare', 'worried', 'handy', 'online', 'needed', 'lightweight', 'amateur', 'brighter', 'promotional', 'rubbery', 'biggest', 'external', 'correct', 'competent', 'versatile', 'perfect', 'lowest', 'complicated', 'affordable', 'tactile', 'audiovisual', 'go', 'third', 'awful', 'broke', 'pointed', 'positive', 'new', 'sure', 'decent', 'relative', 'different', 'stupid', 'flip', 'important', 'following', 'brilliant', 'light', 'fine', 'ready', 'proper', 'complete', 'easier', 'excellent', 'bad', 'comparative', 'recent', 'poor', 'informative', 'additional', 'prominent', 'easy', 'real', 'hollow', 'little', 'back', 'outside', 'left', 'hard', 'useless', 'superior', 'persnickety', 'bulky', 'replaceable', 'manual', 'charged', 'amazing', 'nice', 'wonderful', 'purple', 'forgiving', 'broad', 'main', 'painless', 'jumpy', 'pleased', 'cheap', 'able', 'waste', 'sick', 'stunning', 'same', 'possible', 'inexpensive', 'own', 'available', 'absolute', 'difficult', 'last', 'inclined', 'sharp', 'latest', 'shiny', 'huge', 'awesome', 'upper', 'heavy', 'settled', 'over', 'dark', 'tired', 'timely', 'such', 'slim', 'internal', 'intrusive', 'only', 'current', 'impressed', 'helpful', 'confused', 'defective', 'common', 'newest', 'reasonable', 'going', 'entire', 'expired', 'worth', 'worst', 'earlier', 'convinced', 'anti', 'identical', 'ago', 'wider', 'figured', 'windy', 'coolest', 'minor', 'biting', 'true', 'soft', 'dismayed', 'held', 'appropriate', 'previous', 'intended', 'superb', 'complex', 'horizontal', 'removable', 'physical', 'wrong', 'comparable', 'finished', 'good', 'recorded', 'dirty', 'projected', 'accompanying', 'encouraged', 'inclement', 'quality', 'personal', 'beat', 'high', 'slight', 'automatic', 'small', 'plus', 'digital', 'clear', 'lit', 'alternate', 'outdated', 'one', 'terrible', 'brief', 'whole', 'red', 'capacitive', 'wide', 'sensitive', 'tiny', 'beautiful', 'clean', 'working', 'long', 'elaborate', 'extra', 'size', 'short', 'more', 'unsatisfied', 'serial', 'spacious', 'newer', 'umpteenth', 'due', 'right', 'supposed', 'glossy', 'cheapest', 'customary', 'loud', 'cool', 'full', 'higher', 'underwater', 'obvious', 'rechargeable', 'low'}\n"
     ]
    }
   ],
   "source": [
    "found = set()\n",
    "not_found = set()\n",
    "\n",
    "for opinion, _ in opinions_by_count:\n",
    "    if is_sentiment_bearing(opinion):\n",
    "        found.add(opinion)\n",
    "    else:\n",
    "        not_found.add(opinion)\n",
    "    \n",
    "print(\"NOT FOUND: \" + str(not_found))\n",
    "print(\"FOUND: \" + str(found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Feature cumulative sentiments:\")\n",
    "feature_sentiments_cumulative_sorted = sorted(feature_sentiments_cumulative.items(), key=lambda x: x[1], reverse=True)\n",
    "feature_sentiments_cumulative_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion word sentiments:\n",
      "[('difficult', -1),\n",
      " ('horrible', -1),\n",
      " ('complicated', -1),\n",
      " ('malfunctioning', -1),\n",
      " ('sloppy', -1),\n",
      " ('annoying', -1),\n",
      " ('terrible', -1),\n",
      " ('lousy', -1),\n",
      " ('strange', -1),\n",
      " ('weak', -1),\n",
      " ('bad', -1),\n",
      " ('defective', -1),\n",
      " ('inferior', -1),\n",
      " ('poor', -1),\n",
      " ('unreliable', -1),\n",
      " ('buggy', -1),\n",
      " ('worst', -1),\n",
      " ('useless', -1),\n",
      " ('old', -1),\n",
      " ('misleading', -1),\n",
      " ('miserable', -1),\n",
      " ('mediocre', -1),\n",
      " ('weird', -1),\n",
      " ('unstable', -1),\n",
      " ('outdated', -1),\n",
      " ('unsatisfied', -1),\n",
      " ('suck', -1),\n",
      " ('secondary', -1),\n",
      " ('stayed', -1),\n",
      " ('emailed', -1),\n",
      " ('sound', 0),\n",
      " ('supposed', 0),\n",
      " ('common', 0),\n",
      " ('needs', 0),\n",
      " ('jumpy', 0),\n",
      " ('external', 0),\n",
      " ('worked', 0),\n",
      " ('work', 0),\n",
      " ('flip', 0),\n",
      " ('does', 0),\n",
      " ('same', 0),\n",
      " ('plus', 0),\n",
      " ('works', 0),\n",
      " ('varies', 0),\n",
      " ('recorded', 0),\n",
      " ('professional', 0),\n",
      " ('power', 0),\n",
      " ('second', 0),\n",
      " ('overall', 0),\n",
      " ('fails', 0),\n",
      " ('lit', 0),\n",
      " ('outstanding', 0),\n",
      " ('turn', 0),\n",
      " ('usb', 0),\n",
      " ('effective', 0),\n",
      " ('picture', 0),\n",
      " ('has', 0),\n",
      " ('runs', 0),\n",
      " ('superb', 0),\n",
      " ('audio', 0),\n",
      " ('helpful', 0),\n",
      " ('go', 0),\n",
      " ('last', 0),\n",
      " ('soft', 0),\n",
      " ('heavy', 0),\n",
      " ('underwater', 0),\n",
      " ('whole', 0),\n",
      " ('creative', 0),\n",
      " ('record', 0),\n",
      " ('mic', 0),\n",
      " ('suffers', 0),\n",
      " ('dedicated', 0),\n",
      " ('loud', 0),\n",
      " ('smooth', 0),\n",
      " ('surpasses', 0),\n",
      " ('handheld', 0),\n",
      " ('encouraged', 0),\n",
      " ('regular', 0),\n",
      " ('portable', 0),\n",
      " ('capacitive', 0),\n",
      " ('added', 0),\n",
      " ('entire', 0),\n",
      " ('stay', 0),\n",
      " ('makes', 0),\n",
      " ('informative', 0),\n",
      " ('worth', 0),\n",
      " ('allow', 0),\n",
      " ('match', 0),\n",
      " ('live', 0),\n",
      " ('online', 0),\n",
      " ('netbook', 0),\n",
      " ('due', 0),\n",
      " ('complete', 0),\n",
      " ('ridiculous', 0),\n",
      " ('earlier', 0),\n",
      " ('intended', 0),\n",
      " ('supports', 0),\n",
      " ('manual', 0),\n",
      " ('convinced', 0),\n",
      " ('finished', 0),\n",
      " ('great', 1),\n",
      " ('friendly', 1),\n",
      " ('comfortable', 1),\n",
      " ('precise', 1),\n",
      " ('stunning', 1),\n",
      " ('good', 1),\n",
      " ('perfect', 1),\n",
      " ('exceptional', 1),\n",
      " ('awesome', 1),\n",
      " ('solid', 1),\n",
      " ('clear', 1),\n",
      " ('ideal', 1),\n",
      " ('better', 1),\n",
      " ('vibrant', 1),\n",
      " ('rich', 1),\n",
      " ('excellent', 1),\n",
      " ('simple', 1),\n",
      " ('realistic', 1),\n",
      " ('super', 1),\n",
      " ('best', 1),\n",
      " ('strong', 1),\n",
      " ('easy', 1),\n",
      " ('superior', 1),\n",
      " ('bright', 1),\n",
      " ('amazing', 1),\n",
      " ('nice', 1),\n",
      " ('fantastic', 1),\n",
      " ('impressive', 1),\n",
      " ('intuitive', 1),\n",
      " ('handy', 1),\n",
      " ('sensitive', 1),\n",
      " ('sharp', 1),\n",
      " ('small', 1),\n",
      " ('crisp', 1),\n",
      " ('quick', 1),\n",
      " ('clean', 1),\n",
      " ('lightweight', 1),\n",
      " ('painless', 1),\n",
      " ('brief', 1),\n",
      " ('years', 1),\n",
      " ('is', 1),\n",
      " ('charge', 1),\n",
      " ('increases', 1),\n",
      " ('rechargeable', 1),\n",
      " ('fluctuates', 1),\n",
      " ('beautiful', 1),\n",
      " ('little', 1),\n",
      " ('ago', 1),\n",
      " ('user', 1),\n",
      " ('next', 1),\n",
      " ('available', 1),\n",
      " ('arrived', 1),\n",
      " ('extra', 1),\n",
      " ('funny', 1),\n",
      " ('following', 1),\n",
      " ('spacious', 1),\n",
      " ('photo', 1),\n",
      " ('right', 1),\n",
      " ('boils', 1),\n",
      " ('seems', 1),\n",
      " ('different', 1),\n",
      " ('video', 1),\n",
      " ('new', 1),\n",
      " ('decent', 1),\n",
      " ('bundled', 1),\n",
      " ('tiny', 1),\n",
      " ('acceptable', 1),\n",
      " ('registered', 1),\n",
      " ('high', 1),\n",
      " ('playing', 1),\n",
      " ('else', 1),\n",
      " ('additional', 1),\n",
      " ('more', 1),\n",
      " ('short', 1),\n",
      " ('surprise', 1),\n",
      " ('wide', 1),\n",
      " ('goes', 1),\n",
      " ('included', 1),\n",
      " ('buy', 1),\n",
      " ('flush', 1),\n",
      " ('first', 1),\n",
      " ('size', 1),\n",
      " ('died', 1),\n",
      " ('digital', 1),\n",
      " ('do', 1),\n",
      " ('amateur', 1),\n",
      " ('real', 1),\n",
      " ('need', 1),\n",
      " ('cool', 1),\n",
      " ('higher', 1),\n",
      " ('such', 1),\n",
      " ('types', 1),\n",
      " ('say', 1),\n",
      " ('rare', 1),\n",
      " ('enough', 1),\n",
      " ('much', 1),\n",
      " ('minor', 1),\n",
      " ('projected', 1),\n",
      " ('remains', 1),\n",
      " ('comes', 1),\n",
      " ('affordable', 1),\n",
      " ('quality', 1),\n",
      " ('shooting', 1),\n",
      " ('spare', 1),\n",
      " ('third', 1),\n",
      " ('light', 1),\n",
      " ('fledged', 1),\n",
      " ('compact', 1),\n",
      " ('hard', 1),\n",
      " ('me', 1),\n",
      " ('inches', 1),\n",
      " ('removable', 1),\n",
      " ('brighter', 1),\n",
      " ('only', 1),\n",
      " ('make', 1),\n",
      " ('central', 1),\n",
      " ('lens', 1),\n",
      " ('other', 1),\n",
      " ('there', 1),\n",
      " ('similar', 1),\n",
      " ('ability', 1),\n",
      " ('substantial', 1),\n",
      " ('special', 1),\n",
      " ('integrates', 1),\n",
      " ('easier', 1),\n",
      " ('version', 1),\n",
      " ('try', 1),\n",
      " ('favorite', 1),\n",
      " ('got', 1),\n",
      " ('was', 1),\n",
      " ('lasts', 1),\n",
      " ('long', 1),\n",
      " ('dirty', 1),\n",
      " ('camcorder', 1),\n",
      " ('personal', 1),\n",
      " ('multifunction', 1),\n",
      " ('standard', 1),\n",
      " ('bigger', 1),\n",
      " ('positive', 1),\n",
      " ('cheapest', 1),\n",
      " ('feature', 1),\n",
      " ('inclined', 1),\n",
      " ('lock', 1),\n",
      " ('actual', 1),\n",
      " ('lower', 1),\n",
      " ('low', 1),\n",
      " ('love', 1),\n",
      " ('internal', 1),\n",
      " ('rubber', 1),\n",
      " ('puts', 1),\n",
      " ('replaceable', 1),\n",
      " ('accompanying', 1),\n",
      " ('unintuitive', 1),\n",
      " ('customary', 1),\n",
      " ('takes', 1),\n",
      " ('slim', 1),\n",
      " ('picked', 1),\n",
      " ('choppy', 1),\n",
      " ('happy', 1),\n",
      " ('practical', 1),\n",
      " ('close', 1),\n",
      " ('prominent', 1),\n",
      " ('relative', 1),\n",
      " ('broad', 1),\n",
      " ('held', 1),\n",
      " ('recording', 1),\n",
      " ('accurate', 1),\n",
      " ('glossy', 1),\n",
      " ('upper', 1),\n",
      " ('prompted', 1),\n",
      " ('recent', 1),\n",
      " ('have', 1),\n",
      " ('unlimited', 1),\n",
      " ('possible', 1),\n",
      " ('settled', 1),\n",
      " ('over', 1),\n",
      " ('white', 1),\n",
      " ('allowed', 1),\n",
      " ('purple', 1),\n",
      " ('charging', 1),\n",
      " ('about', 1),\n",
      " ('look', 1),\n",
      " ('desktop', 1),\n",
      " ('newest', 1),\n",
      " ('big', 1),\n",
      " ('hemorrhaging', 1),\n",
      " ('flimsyindependent', 1),\n",
      " ('newer', 1),\n",
      " ('prone', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Opinion word sentiments:\")\n",
    "pprint(sorted(opinion_sentiments.items(), key=lambda x:x[1], reverse=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Newly discovered opinion words:\")\n",
    "pprint(opinions.difference(positive_lexicon.union(negative_lexicon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = {}\n",
    "for i in review_indices:\n",
    "    compiled_results[i] = {}\n",
    "    compiled_results[i]['opinion_words'] = opinion_words_by_review[i]\n",
    "    compiled_results[i]['feature_sentiments'] = feature_sentiments_by_review[i]\n",
    "    \n",
    "pprint(compiled_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews(features, opinions, parsed_sentences, review_indices, raw_sentences, feature_sentiments_by_review):\n",
    "    FO_dict = defaultdict(list)\n",
    "    j = 0\n",
    "    k = -1\n",
    "    for i, sentence in enumerate(parsed_sentences):\n",
    "        phrase_dict = {}\n",
    "        FO_dict_sentence = defaultdict(list)\n",
    "        review_index = review_indices[i]\n",
    "        if review_index != review_indices[i-1]:\n",
    "            j = 0\n",
    "            print(\"==========================================\\n\\nReview #{}\".format(review_index))\n",
    "        else:\n",
    "            j += 1\n",
    "        k += 1\n",
    "        print(\"\\n\\tSentence #{}\".format(j))\n",
    "        print(\"\\t{}\".format(raw_sentences[k]))\n",
    "        for (gov, gov_pos), dependency, (dep, dep_pos) in sentence:\n",
    "            if not gov.isalpha() or not dep.isalpha():\n",
    "                continue\n",
    "            gov = gov.lower()\n",
    "            dep = dep.lower()\n",
    "            if dependency == \"nsubj\" and dep in features:\n",
    "                FO_dict_sentence[dep].append(gov)\n",
    "                print(\"\\t\\tnsubj: {} -> {}, {}\".format(gov, dep, feature_sentiments_by_review[review_index][dep]))\n",
    "            elif dependency == \"amod\" and gov in features:\n",
    "                FO_dict_sentence[gov].append(dep)\n",
    "                print(\"\\t\\tamod: {} -> {}, {}\".format(dep, gov, feature_sentiments_by_review[review_index][gov]))\n",
    "            elif dependency == \"compound\" and gov in features:\n",
    "                phrase_dict[gov] = dep + \" \" + gov\n",
    "        for feature, opinions in FO_dict_sentence.items():\n",
    "            if feature in phrase_dict:\n",
    "                FO_dict[phrase_dict[feature]] += opinions\n",
    "            else:\n",
    "                FO_dict[feature] += opinions\n",
    "    return FO_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews(features,\n",
    "                opinions,\n",
    "                parsed_sentences,\n",
    "                review_indices,\n",
    "                raw_sentences,\n",
    "                feature_sentiments_by_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some notes\n",
    "\n",
    "# still need to handle negations\n",
    "\n",
    "# \"due to the two observations, multiple polarities may be assigned to an opinion word or target\"\n",
    "#   we should keep a running total of observations\n",
    "#   num_negative_sentiments = total_observations - cumulative_polarity\n",
    "\n",
    "# if target is from another review, we use the cumulative polarity to assign sentiment to the opinion word\n",
    "#   should we also assign the cumulative polarity to the target itself?\n",
    "#   we are right now, that way every observed feature gets a sentiment for each occurence\n",
    "\n",
    "# CCB: compute opinion sentiment priors based on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most reviewed asins\n",
    "top_asins = asins[:30]\n",
    "pprint(top_asins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug and play\n",
    "asin_ = \"B003ELYQGG\"\n",
    "\n",
    "reviews_ = get_all_reviews(asin_)\n",
    "\n",
    "features_, \\\n",
    "features_count_, \\\n",
    "opinions_, \\\n",
    "opinions_count_, \\\n",
    "raw_sentences_, \\\n",
    "parsed_sentences_, \\\n",
    "review_indices_, \\\n",
    "feature_sentiments_by_review_, \\\n",
    "feature_words_by_review_, \\\n",
    "feature_sentiments_cumulative_, \\\n",
    "feature_sentiments_pos_, \\\n",
    "feature_sentiments_neg_, \\\n",
    "opinion_words_by_review_, \\\n",
    "opinion_sentiments_ = extract_features_opinions(reviews_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature words, occurrences:\")\n",
    "features_by_count_ = sorted(features_count_.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(features_by_count_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_classes = get_sorted_classes(features_by_count_)\n",
    "pprint(sorted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Opinion words, occurrences:\")\n",
    "opinions_by_count_ = sorted(opinions_count_.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(opinions_by_count_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature cumulative sentiments:\")\n",
    "feature_sentiments_cumulative_sorted_ = sorted(feature_sentiments_cumulative_.items(), key=lambda x: x[1], reverse=True)\n",
    "feature_sentiments_cumulative_sorted_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Opinion word sentiments:\")\n",
    "pprint(sorted(opinion_sentiments_.items(), key=lambda x:x[1], reverse=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Newly discovered opinion words:\")\n",
    "pprint(opinions_.difference(positive_lexicon.union(negative_lexicon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews(features_,\n",
    "                opinions_,\n",
    "                parsed_sentences_,\n",
    "                review_indices_,\n",
    "                raw_sentences_,\n",
    "                feature_sentiments_by_review_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk processing\n",
    "asins_to_process = asins[:20]\n",
    "product_infos = {}\n",
    "for i, (asin, _) in enumerate(asins_to_process):\n",
    "    try:\n",
    "        print('{}, {}\\n'.format(i, asin))\n",
    "        product_reviews = get_all_reviews(asin)\n",
    "\n",
    "        product_info = {}\n",
    "        product_info['features'], \\\n",
    "        product_info['features_count'], \\\n",
    "        product_info['opinions'], \\\n",
    "        product_info['opinions_count'], \\\n",
    "        product_info['raw_sentences'], \\\n",
    "        product_info['parsed_sentences'], \\\n",
    "        product_info['review_indices'], \\\n",
    "        product_info['feature_sentiments_by_review'], \\\n",
    "        product_info['feature_words_by_review'], \\\n",
    "        product_info['feature_sentiments_cumulative'], \\\n",
    "        product_info['feature_sentiments_pos'], \\\n",
    "        product_info['feature_sentiments_neg'], \\\n",
    "        product_info['opinion_words_by_review'], \\\n",
    "        product_info['opinion_sentiments'] = extract_features_opinions(product_reviews)\n",
    "        \n",
    "        product_infos[asin] = product_info\n",
    "    except ValueError as e:\n",
    "        product_infos[asin] = {'error' : str(e)}\n",
    "        print('Could not process product {} ({})'.format(asin, str(e)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: remove non-english reviews to avoid errors such as \"Invalid control character at: line 1 column 23732 (char 23731)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for asin,product_info in list(product_infos.items())[1:2]:\n",
    "    if 'error' not in product_info:\n",
    "        print('ASIN: {}'.format(asin))\n",
    "        \n",
    "        print('# of Positive Sentiments')\n",
    "        feature_sentiments_pos_sorted = sorted([(k,len(v)) for k,v in product_info['feature_sentiments_pos'].items()], key=lambda x: x[1], reverse=True)\n",
    "        pprint(feature_sentiments_pos_sorted[:15])\n",
    "        \n",
    "        print('# of Negative Sentiments')\n",
    "        feature_sentiments_neg_sorted = sorted([(k,len(v)) for k,v in product_info['feature_sentiments_neg'].items()], key=lambda x: x[1], reverse=True)\n",
    "        pprint(feature_sentiments_neg_sorted[:15])\n",
    "        \n",
    "        feature = feature_sentiments_neg_sorted[0][0]\n",
    "        print('FEATURE: {}'.format(feature))\n",
    "        for review_num, words in product_info['feature_words_by_review'].items():\n",
    "            if feature in words:\n",
    "                if product_info['feature_sentiments_by_review'][review_num][feature] < 0:\n",
    "                    print(review_num, product_info['feature_sentiments_by_review'][review_num][feature])\n",
    "                    for sentence_num,review_num_ in enumerate(product_info['review_indices']):\n",
    "                        if review_num == review_num_:\n",
    "                            sentence = product_info['raw_sentences'][sentence_num]\n",
    "                            if feature in [w.lower() for w in sentence.split()]:\n",
    "                                print(sentence)\n",
    "\n",
    "#                print([product_info['raw_sentences'][sentence_num] \\\n",
    "#                       for sentence_num,review_num in enumerate(product_info['review_indices']) \\\n",
    "#                       if feature in product_info['feature_words_by_review'][review_num] ])                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_infos['B00DR0PDNE']['opinion_words_by_review']\n",
    "pprint([(a,b) for a,b in {k:list(filter(lambda w: (product_infos['B00DR0PDNE']['opinion_sentiments'][w] < 0),v)) for k,v in product_infos['B00DR0PDNE']['opinion_words_by_review'].items()}.items() if len(b)>0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_infos['B00DR0PDNE']['opinion_sentiments']['amazon']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(product_infos['B000LRMS66']['raw_sentences']))\n",
    "print(len(product_infos['B000LRMS66']['feature_words_by_review']))\n",
    "print(product_infos['B000LRMS66']['review_indices'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible statistics\n",
    "# # pos sentiments vs # neg sentiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
