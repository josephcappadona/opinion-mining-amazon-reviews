{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from pprint import pprint\n",
    "\n",
    "config = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"database\": \"senior_design\"\n",
    "}\n",
    "connection = mysql.connector.connect(**config)\n",
    "cursor = connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT distinct asin, COUNT(asin) AS count FROM review GROUP BY asin ORDER BY count DESC\"\n",
    "cursor.execute(query)\n",
    "asins = []\n",
    "for asin, count in cursor:\n",
    "    asins.append((asin,count))\n",
    "asins = sorted(asins, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B000Q3IUV2', 158),\n",
      " ('B000QSN3O6', 158),\n",
      " ('B000TXNS6G', 158),\n",
      " ('B000J1CCGA', 158),\n",
      " ('B000GYU9IS', 158)]\n"
     ]
    }
   ],
   "source": [
    "pprint(asins[8000:8005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reviews(asin):\n",
    "    query = \"SELECT review_text FROM review WHERE asin = '{}'\".format(asin)\n",
    "    cursor.execute(query)\n",
    "    reviews = []\n",
    "    for (review_text) in cursor:\n",
    "        reviews.append(review_text[0])\n",
    "    print(\"# reviews: {}\".format(len(reviews)))\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lexicon = {\"good\", \"great\", \"better\", \"excellent\", \"best\", \"easy\", \"nice\", \"simple\", \"clear\", \"strong\", \n",
    "                    \"perfect\", \"comfortable\", \"friendly\", \"solid\", \"precise\", \"awesome\", \"amazing\", \"bright\", \"vibrant\",\n",
    "                    \"fantastic\", \"vibrant\", \"realistic\", \"stunning\", \"superior\", \"super\", \"rich\", \"exceptional\",\n",
    "                    \"impressive\", \"ideal\"}\n",
    "negative_lexicon = {\"poor\", \"old\", \"bad\", \"weak\", \"annoying\", \"defective\", \"horrible\", \"buggy\", \"worst\", \"mediocre\",\n",
    "                    \"difficult\", \"unstable\", \"inferior\", \"lousy\", \"complicated\", \"useless\", \"unreliable\", \"sloppy\",\n",
    "                    \"strange\", \"weird\", \"malfunctioning\", \"miserable\", \"terrible\", \"misleading\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "# Start the CoreNLP server with:\n",
    "# java -mx4g -cp \"./CoreNLP/*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "#     (on my Mac, java8 bin located at /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java)\n",
    "nlp = CoreNLPDependencyParser(url=\"http://localhost:9000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# input: parsed_sentence, cumulative information dictionaries (FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count)\n",
    "# output: extracted dependency features\n",
    "def extract_relevant_dependencies(parsed_sentence, FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count):\n",
    "    extracted_sentence = []\n",
    "    for (gov, gov_pos), dependency, (dep, dep_pos) in parsed_sentence.triples():\n",
    "        if not gov.isalpha() or not dep.isalpha():\n",
    "            continue\n",
    "        gov = gov.lower()\n",
    "        dep = dep.lower()\n",
    "        if dependency == \"nsubj\" and dep_pos == \"NN\":\n",
    "            OF_dict[gov] = dep\n",
    "            FO_dict[dep] = gov\n",
    "            features_count[dep] += 1\n",
    "            opinions_count[gov] += 1\n",
    "        elif dependency == \"amod\" and gov_pos == \"NN\":\n",
    "            OF_dict[dep] = gov\n",
    "            FO_dict[gov] = dep\n",
    "            opinions_count[dep] += 1\n",
    "            features_count[gov] += 1\n",
    "        elif dependency == \"conj\":\n",
    "            if gov_pos == \"JJ\" and dep_pos == \"JJ\":\n",
    "                OO_dict[gov].append(dep)\n",
    "                OO_dict[dep].append(gov)\n",
    "                opinions_count[gov] += 1\n",
    "                opinions_count[dep] += 1\n",
    "            elif gov_pos == \"NN\" and dep_pos == \"NN\":\n",
    "                FF_dict[gov].append(dep)\n",
    "                FF_dict[dep].append(gov)\n",
    "                features_count[gov] += 1\n",
    "                features_count[dep] += 1\n",
    "        extracted_sentence.append(((gov, gov_pos), dependency, (dep, dep_pos)))\n",
    "    #parsed_sentences.append(extracted_sentence)\n",
    "    return extracted_sentence\n",
    "\n",
    "\n",
    "# input: all_review_info, cumulative information dictionaries\n",
    "# output: new_features, new_opinions\n",
    "def double_propagation_iterate(all_review_info,\n",
    "                               features,\n",
    "                               feature_words_by_review,\n",
    "                               feature_sentiments_by_review,\n",
    "                               feature_sentiments_cumulative,\n",
    "                               feature_sentiments_pos,\n",
    "                               feature_sentiments_neg,\n",
    "                               opinions,\n",
    "                               opinion_words_by_review,\n",
    "                               opinion_sentiments):\n",
    "    new_opinions = set()\n",
    "    new_features = set()\n",
    "\n",
    "    for index, info in all_review_info.items():\n",
    "        feature_sentiments_by_review[index] = defaultdict(int)\n",
    "\n",
    "        for opinion, feature in info['OF_dict'].items():\n",
    "            if opinion in opinions:\n",
    "                if feature not in features:\n",
    "                    new_features.add(feature)\n",
    "\n",
    "                if feature not in feature_words_by_review[index]:\n",
    "                    feature_words_by_review[index].add(feature)\n",
    "\n",
    "                    # target takes polarity of modifying opinion word\n",
    "                    feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                    # add to target's cumulative sentiment score\n",
    "                    feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                    if opinion_sentiments[opinion] > 0:\n",
    "                        feature_sentiments_pos[feature].append(info['index'])\n",
    "                    elif opinion_sentiments[opinion] < 0:\n",
    "                        feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "                # have we seen this opinion word in this review?\n",
    "                if opinion not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "        for opinion1, related in info['OO_dict'].items():\n",
    "            if opinion1 in opinions:\n",
    "                for opinion in related:\n",
    "                    if opinion not in opinions:\n",
    "                        new_opinions.add(opinion)\n",
    "                        opinion_sentiments[opinion] = opinion_sentiments[opinion1]\n",
    "\n",
    "                    # have we seen this opinion word in this review?\n",
    "                    if opinion not in opinion_words_by_review[index]:\n",
    "                        opinion_words_by_review[index].add(opinion)\n",
    "                        info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "                # have we seen this opinion word in this review?\n",
    "                if opinion1 not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion1)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion1]\n",
    "\n",
    "        for feature, opinion in info['FO_dict'].items():\n",
    "            if feature in features:\n",
    "                if opinion not in opinions:\n",
    "                    new_opinions.add(opinion)\n",
    "\n",
    "                    # if target has sentiment in current review\n",
    "                    if feature in feature_words_by_review[index]:\n",
    "                        # then opinion takes polarity of target (Homogenous Rule)\n",
    "                        opinion_sentiments[opinion] = feature_sentiments_by_review[index][feature]\n",
    "                    else:\n",
    "                        # else target is from another review\n",
    "                        # opinion takes cumulative sentiment of entire review (Intra-review Rule)\n",
    "                        try:\n",
    "                            cumulative_polarity = int(info['cumulative_polarity'] / abs(info['cumulative_polarity']))\n",
    "                        except ZeroDivisionError:\n",
    "                            cumulative_polarity = 0\n",
    "                        opinion_sentiments[opinion] = cumulative_polarity\n",
    "\n",
    "                        # also apply that polarity to the feature (should we do this?)\n",
    "                        feature_words_by_review[index].add(feature)\n",
    "                        feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                        # add to target's cumulative sentiment\n",
    "                        feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                        if opinion_sentiments[opinion] > 0:\n",
    "                            feature_sentiments_pos[feature].append(info['index'])\n",
    "                        elif opinion_sentiments[opinion] < 0:\n",
    "                            feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "                if opinion not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "                if feature not in feature_sentiments_by_review[index]:\n",
    "                    feature_words_by_review[index].add(feature)\n",
    "                    feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                    # add to target's cumulative sentiment\n",
    "                    feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                    if opinion_sentiments[opinion] > 0:\n",
    "                        feature_sentiments_pos[feature].append(info['index'])\n",
    "                    elif opinion_sentiments[opinion] < 0:\n",
    "                        feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "        for feature1, related in info['FF_dict'].items():\n",
    "            if feature1 in features and feature1 in feature_sentiments_by_review[index]:\n",
    "                for feature in related:\n",
    "                    if feature not in features:\n",
    "                        new_features.add(feature)\n",
    "\n",
    "                    # have we seen this target word in this review?\n",
    "                    if feature not in feature_words_by_review[index]:\n",
    "                        feature_words_by_review[index].add(feature)\n",
    "\n",
    "                        # Homogenous Rule\n",
    "                        feature_sentiments_by_review[index][feature] = feature_sentiments_by_review[index][feature1]\n",
    "                        feature_sentiments_cumulative[feature] += feature_sentiments_by_review[index][feature]\n",
    "                        if feature_sentiments_by_review[index][feature] > 0:\n",
    "                            feature_sentiments_pos[feature].append(info['index'])\n",
    "                        elif feature_sentiments_by_review[index][feature] < 0:\n",
    "                            feature_sentiments_neg[feature].append(info['index'])\n",
    "    return new_features, new_opinions\n",
    "\n",
    "\n",
    "# input: list of review texts\n",
    "# output: all features, expanded opinion lexicon\n",
    "def extract_features_opinions(reviews):\n",
    "    features = set()\n",
    "    features_count = defaultdict(int)\n",
    "    opinions = positive_lexicon.union(negative_lexicon)\n",
    "    opinions_count = defaultdict(int)\n",
    "    \n",
    "    raw_sentences = []\n",
    "    parsed_sentences = []\n",
    "    parses = []\n",
    "    review_indices = []\n",
    "    review_info = {} # store info about deps on per review basis\n",
    "    for i, review in enumerate(reviews):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        OF_dict = {}\n",
    "        FO_dict = {}\n",
    "        OO_dict = defaultdict(list)\n",
    "        FF_dict = defaultdict(list)\n",
    "        \n",
    "        raw_sentences.extend(sent_tokenize(review))\n",
    "        parse = nlp.parse_text(review)\n",
    "        parses.append(parse)\n",
    "        try:\n",
    "            for sentence in parse:\n",
    "                # extract relevant dependency information\n",
    "                extracted_sentence = extract_relevant_dependencies(sentence, FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count)\n",
    "\n",
    "                review_indices.append(i)\n",
    "                parsed_sentences.append(extracted_sentence)\n",
    "        except ValueError:\n",
    "            # probably not English\n",
    "            pass\n",
    "\n",
    "        review_info[i] = { 'index' : i,\n",
    "                           'OF_dict' : OF_dict,\n",
    "                           'FO_dict' : FO_dict,\n",
    "                           'OO_dict' : OO_dict,\n",
    "                           'FF_dict' : FF_dict,\n",
    "                           'cumulative_polarity' : 0 }\n",
    "\n",
    "    # instantiate cumulative data structures\n",
    "    i = 0\n",
    "    feature_sentiments_by_review = defaultdict(dict) # same sentiment for target words within review (this is an assumption [Observation 1])\n",
    "    feature_sentiments_cumulative = defaultdict(int)\n",
    "    feature_sentiments_pos = defaultdict(list) # keep track of the review indices that contributed negative sentiments toward each feature\n",
    "    feature_sentiments_neg = defaultdict(list) # keep track of the review indices that contributed negative sentiments toward each feature\n",
    "    feature_words_by_review = defaultdict(set) # keep track of the feature words in each review\n",
    "    opinion_words_by_review = defaultdict(set) # keep track of the opinion words in each review\n",
    "    opinion_sentiments = {} # same sentiment for opinion words throughout the corpus (this is an assumption [Observation 2])\n",
    "    opinion_sentiments.update({op:(1 if op in positive_lexicon else -1) for op in opinions})\n",
    "\n",
    "    while (True):\n",
    "        print(\"DP Iteration: {}\".format(i))\n",
    "        i += 1\n",
    "\n",
    "        # double propagation step\n",
    "        new_features, \\\n",
    "        new_opinions = double_propagation_iterate(review_info,\n",
    "                                                  features,\n",
    "                                                  feature_words_by_review,\n",
    "                                                  feature_sentiments_by_review,\n",
    "                                                  feature_sentiments_cumulative,\n",
    "                                                  feature_sentiments_pos,\n",
    "                                                  feature_sentiments_neg,\n",
    "                                                  opinions,\n",
    "                                                  opinion_words_by_review,\n",
    "                                                  opinion_sentiments)\n",
    "        \n",
    "        features = features.union(new_features)\n",
    "        opinions = opinions.union(new_opinions)\n",
    "        if len(new_opinions) == 0 and len(new_features) == 0:\n",
    "            break\n",
    "\n",
    "    res = (features,\n",
    "           features_count,\n",
    "           opinions,\n",
    "           opinions_count,\n",
    "           raw_sentences,\n",
    "           parsed_sentences,\n",
    "           review_indices,\n",
    "           feature_sentiments_by_review,\n",
    "           feature_words_by_review,\n",
    "           feature_sentiments_cumulative,\n",
    "           feature_sentiments_pos,\n",
    "           feature_sentiments_neg,\n",
    "           opinion_words_by_review,\n",
    "           opinion_sentiments)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product quality clustering\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "CLASS_FILE = \"./clustering/results/clean-classes.pkl\"\n",
    "feature_to_class = pickle.load(open(CLASS_FILE, 'rb'))\n",
    "\n",
    "def get_sorted_classes(features_by_count):\n",
    "    frequent_features = [(f, cnt) for f, cnt in features_by_count if cnt >= 5]\n",
    "    features_by_class = dict()\n",
    "    not_found = set()\n",
    "\n",
    "    # features_by_class is a dict from class number -> [feature list, total count]\n",
    "    for feature, cnt in frequent_features:\n",
    "        if feature not in feature_to_class:\n",
    "            not_found.add(feature)\n",
    "            continue\n",
    "        class_num = feature_to_class[feature]\n",
    "        if class_num not in features_by_class:\n",
    "            features_by_class[class_num] = [[], 0]\n",
    "        features_by_class[class_num][0].append(feature)\n",
    "        features_by_class[class_num][1] += cnt\n",
    "\n",
    "    sorted_classes = sorted(features_by_class.values(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Not found in any cluster: \" + str(not_found))\n",
    "    return sorted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_asin(asin):\n",
    "    feature_to_class = pickle.load(open(\"./clustering/results/clean-classes.pkl\", \"rb\"))\n",
    "    print(asin)\n",
    "    product_reviews = get_all_reviews(asin)\n",
    "\n",
    "    product_info = {'asin':asin}\n",
    "    product_info['features'], \\\n",
    "    product_info['features_count'], \\\n",
    "    product_info['opinions'], \\\n",
    "    product_info['opinions_count'], \\\n",
    "    product_info['raw_sentences'], \\\n",
    "    product_info['parsed_sentences'], \\\n",
    "    product_info['review_indices'], \\\n",
    "    product_info['feature_sentiments_by_review'], \\\n",
    "    product_info['feature_words_by_review'], \\\n",
    "    product_info['feature_sentiments_cumulative'], \\\n",
    "    product_info['feature_sentiments_pos'], \\\n",
    "    product_info['feature_sentiments_neg'], \\\n",
    "    product_info['opinion_words_by_review'], \\\n",
    "    product_info['opinion_sentiments'] = extract_features_opinions(product_reviews)\n",
    "\n",
    "    features_by_count = sorted(product_info['features_count'].items(), key=lambda x: x[1], reverse=True)\n",
    "    product_info['features_by_count'] = features_by_count\n",
    "    \n",
    "    product_info['sorted_classes'] = get_sorted_classes(features_by_count)\n",
    "\n",
    "    return product_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B000CRFOMK\n",
      "# reviews: 770\n",
      "0\n",
      "500\n",
      "DP Iteration: 0\n",
      "DP Iteration: 1\n",
      "DP Iteration: 2\n",
      "DP Iteration: 3\n",
      "DP Iteration: 4\n",
      "DP Iteration: 5\n",
      "DP Iteration: 6\n",
      "DP Iteration: 7\n",
      "DP Iteration: 8\n",
      "Not found in any cluster: {'solution', 'something', 'anyone', 'issue', 'work', 'everything', 'side', 'rating', 'job', 'nothing', 'idea', 'use', 'thing', 'product', 'equipment', 'duty', 'everyone', 'lot', 'problem', 'purpose'}\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "asins_to_process = [asins[1000]]\n",
    "product_infos = {}\n",
    "\n",
    "for asin,_ in asins_to_process:\n",
    "    product_infos[asin] = process_asin(asin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, pickle, time\n",
    "\n",
    "OUTPUT_DIR = 'output/product_info' \n",
    "pathlib.Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "for asin, product_info in product_infos.items():\n",
    "    \n",
    "    with open('{}/{}.pkl'.format(OUTPUT_DIR, asin), 'wb') as handle:\n",
    "        pickle.dump(product_info, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_detailed_summary(product_info):\n",
    "    features = product_info['features']\n",
    "    opinions = product_info['opinions']\n",
    "    parsed_sentences = product_info['parsed_sentences']\n",
    "    review_indices = product_info['review_indices']\n",
    "    raw_sentences = product_info['raw_sentences']\n",
    "    feature_sentiments_by_review = product_info['feature_sentiments_by_review']\n",
    "    j = 0\n",
    "    k = -1\n",
    "    for i, sentence in enumerate(parsed_sentences):\n",
    "        phrase_dict = {}\n",
    "        review_index = review_indices[i]\n",
    "        if review_index != review_indices[i-1]:\n",
    "            j = 0\n",
    "            print(\"==========================================\\n\\nReview #{}\".format(review_index))\n",
    "        else:\n",
    "            j += 1\n",
    "        k += 1\n",
    "        print(\"\\n\\tSentence #{}\".format(j))\n",
    "        print(\"\\t{}\".format(raw_sentences[k]))\n",
    "        for (gov, gov_pos), dependency, (dep, dep_pos) in sentence:\n",
    "            if not gov.isalpha() or not dep.isalpha():\n",
    "                continue\n",
    "            gov = gov.lower()\n",
    "            dep = dep.lower()\n",
    "            if dependency == \"nsubj\" and dep in features:\n",
    "                print(\"\\t\\tnsubj: {} -> {}, {}\".format(gov, dep, feature_sentiments_by_review[review_index][dep]))\n",
    "            elif dependency == \"amod\" and gov in features:\n",
    "                print(\"\\t\\tamod: {} -> {}, {}\".format(dep, gov, feature_sentiments_by_review[review_index][gov]))\n",
    "            elif dependency == \"compound\" and gov in features:\n",
    "                phrase_dict[gov] = dep + \" \" + gov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_detailed_summary(product_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('product_infos.pkl', 'rb') as handle:\n",
    "    product_infos = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ADD TO DOUBLE_PROP.PY\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# quality cluster table\n",
    "def get_quality_clusters(asin):\n",
    "    quality_clusters = []\n",
    "    \n",
    "    product_info = product_infos[asin]\n",
    "    clusters_dict = defaultdict(list)\n",
    "    feature_to_class = pickle.load(open(\"./clustering/results/classes.pkl\", \"rb\"))\n",
    "    features_by_count = sorted(product_info['features_count'].items(), key=lambda x:x[1], reverse=True)\n",
    "    for feature, _ in features_by_count:\n",
    "        try:\n",
    "            class_of_feature = feature_to_class[feature]\n",
    "            clusters_dict[class_of_feature].append(feature)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    clusters = list(clusters_dict.values())\n",
    "\n",
    "    class_of_cluster = {}\n",
    "    clusters_inverse = {}\n",
    "    cluster_sentiments = {}\n",
    "    for id_, cluster_features in enumerate(clusters):\n",
    "        cluster_sentiment = [0, 0] # [pos, neg]\n",
    "        for feature in cluster_features:\n",
    "            clusters_inverse[feature] = id_\n",
    "            class_of_cluster[id_] = feature_to_class[feature]\n",
    "            cluster_sentiment[0] += len(product_info['feature_sentiments_pos'][feature])\n",
    "            cluster_sentiment[1] += len(product_info['feature_sentiments_neg'][feature])\n",
    "        cluster_sentiments[id_] = cluster_sentiment\n",
    "    for cluster_id, sentiments in cluster_sentiments.items():\n",
    "        class_id = class_of_cluster[cluster_id]\n",
    "        cluster_features = clusters_dict[class_id]\n",
    "        num_positive = cluster_sentiments[cluster_id][0]\n",
    "        num_negative = cluster_sentiments[cluster_id][1]\n",
    "        quality_clusters.append((asin, class_id, cluster_id, cluster_features, num_positive, num_negative))\n",
    "    product_info['cluster_sentiments'] = cluster_sentiments\n",
    "    product_info['class_of_cluster'] = class_of_cluster\n",
    "    product_info['clusters'] = clusters\n",
    "    return quality_clusters\n",
    "\n",
    "\n",
    "# product-quality relationship table\n",
    "def get_product_quality_relationships(asin):\n",
    "    product_quality_relationships = []\n",
    "    product_info = product_infos[asin]\n",
    "    clusters = product_info['clusters']\n",
    "    cluster_sentiments = product_info['cluster_sentiments']\n",
    "    class_of_cluster = product_info['class_of_cluster']\n",
    "    for id_, cluster in enumerate(clusters):\n",
    "        quality_cluster_id = id_\n",
    "        quality_list = clusters[id_]\n",
    "        num_positive = cluster_sentiments[id_][0]\n",
    "        num_negative = cluster_sentiments[id_][1]\n",
    "        \n",
    "        for feature in cluster:\n",
    "            quality = feature\n",
    "            quality_class_id = class_of_cluster[id_]\n",
    "            num_positive = len(product_info['feature_sentiments_pos'][feature])\n",
    "            num_negative = len(product_info['feature_sentiments_neg'][feature])\n",
    "            product_quality_relationships.append((asin, quality, quality_cluster_id, quality_class_id, num_positive, num_negative))\n",
    "    return product_quality_relationships\n",
    "\n",
    "\n",
    "# product quality class table\n",
    "def get_class_table(feature_to_class)\n",
    "    classes = defaultdict(list)\n",
    "    for feature, class_ in feature_to_class.items():\n",
    "        classes[class_].append(feature)\n",
    "    classes = sorted(classes.items(), key=lambda x: x[0])\n",
    "    \n",
    "    return classes\n",
    "\n",
    "product_quality_class_table_columns = ['id', 'quality_list']\n",
    "product_quality_class_table = get_class_table(feature_to_class)\n",
    "\n",
    "product_quality_relationship_table = []\n",
    "quality_clusters_table = []\n",
    "\n",
    "for asin, _ in [asins[35]]:\n",
    "    quality_clusters = get_quality_clusters(asin)\n",
    "    quality_clusters_table.extend(quality_clusters)\n",
    "    \n",
    "    product_quality_relationships = get_product_quality_relationships(asin)\n",
    "    product_quality_relationship_table.extend(product_quality_relationships)\n",
    "quality_clusters_table_columns = ['asin', 'class_id', 'quality_cluster_id', 'quality_list', 'num_positive', 'num_negative']\n",
    "quality_clusters_table = sorted(quality_clusters_table, key=lambda x: x[4]+x[5], reverse=True)\n",
    "\n",
    "product_quality_relationship_table_columns = ['asin', 'quality', 'quality_cluster_id', 'quality_class_id', 'num_positive', 'num_negative']\n",
    "product_quality_relationship_table = sorted(product_quality_relationship_table, key=lambda x: x[4]+x[5], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B003DZ165W', 'cover', 169, 208, 7405, 484),\n",
       " ('B003DZ165W', 'light', 340, 433, 7089, 363),\n",
       " ('B003DZ165W', 'kindle', 169, 208, 2325, 223),\n",
       " ('B003DZ165W', 'product', 226, 288, 2283, 86),\n",
       " ('B003DZ165W', 'case', 169, 208, 2190, 175)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_quality_relationship_table[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B003DZ165W',\n",
       "  208,\n",
       "  169,\n",
       "  ['cover',\n",
       "   'kindle',\n",
       "   'case',\n",
       "   'leather',\n",
       "   'protection',\n",
       "   'tab',\n",
       "   'bulk',\n",
       "   'closure',\n",
       "   'flap',\n",
       "   'clasp',\n",
       "   'spine',\n",
       "   'ipad',\n",
       "   'fire',\n",
       "   'tablet',\n",
       "   'folio',\n",
       "   'closing',\n",
       "   'kindel',\n",
       "   'portfolio',\n",
       "   'glove',\n",
       "   'snug',\n",
       "   'paperwhite'],\n",
       "  14162,\n",
       "  964),\n",
       " ('B003DZ165W',\n",
       "  433,\n",
       "  340,\n",
       "  ['light',\n",
       "   'lighting',\n",
       "   'night',\n",
       "   'illumination',\n",
       "   'darkness',\n",
       "   'brightness',\n",
       "   'intensity',\n",
       "   'booklight',\n",
       "   'dark',\n",
       "   'dim',\n",
       "   'flashlight',\n",
       "   'shine',\n",
       "   'backlight',\n",
       "   'spotlight',\n",
       "   'shone',\n",
       "   'dimmer'],\n",
       "  8482,\n",
       "  434),\n",
       " ('B003DZ165W',\n",
       "  288,\n",
       "  226,\n",
       "  ['product',\n",
       "   'item',\n",
       "   'purchase',\n",
       "   'shipping',\n",
       "   'delivery',\n",
       "   'seller',\n",
       "   'order',\n",
       "   'manner',\n",
       "   'company',\n",
       "   'transaction',\n",
       "   'shipment',\n",
       "   'merchant',\n",
       "   'fashion',\n",
       "   'promptness',\n",
       "   'vendor',\n",
       "   'merchandise'],\n",
       "  3084,\n",
       "  155),\n",
       " ('B003DZ165W',\n",
       "  102,\n",
       "  79,\n",
       "  ['corner',\n",
       "   'side',\n",
       "   'right',\n",
       "   'left',\n",
       "   'spot',\n",
       "   'bottom',\n",
       "   'front',\n",
       "   'top',\n",
       "   'rest',\n",
       "   'placement',\n",
       "   'center',\n",
       "   'arrangement',\n",
       "   'seating',\n",
       "   'middle',\n",
       "   'the'],\n",
       "  1911,\n",
       "  100),\n",
       " ('B003DZ165W',\n",
       "  488,\n",
       "  381,\n",
       "  ['price',\n",
       "   'money',\n",
       "   'buy',\n",
       "   'cost',\n",
       "   'tag',\n",
       "   'penny',\n",
       "   'pricy',\n",
       "   'cash',\n",
       "   'pricewise',\n",
       "   'buying',\n",
       "   'bargain',\n",
       "   'fraction',\n",
       "   'premium'],\n",
       "  1438,\n",
       "  84),\n",
       " ('B003DZ165W', 47, 35, ['quality', 'value', 'overall'], 1211, 55),\n",
       " ('B003DZ165W',\n",
       "  268,\n",
       "  214,\n",
       "  ['husband',\n",
       "   'wife',\n",
       "   'daughter',\n",
       "   'gift',\n",
       "   'partner',\n",
       "   'friend',\n",
       "   'son',\n",
       "   'spouse',\n",
       "   'girlfriend',\n",
       "   'sister',\n",
       "   'boyfriend',\n",
       "   'birthday',\n",
       "   'grandson',\n",
       "   'granddaughter',\n",
       "   'hubby',\n",
       "   'mother',\n",
       "   'brother',\n",
       "   'mom',\n",
       "   'girl',\n",
       "   'father',\n",
       "   'dad',\n",
       "   'grandchild',\n",
       "   'nephew',\n",
       "   'niece',\n",
       "   'family',\n",
       "   'wishlist',\n",
       "   'graduation',\n",
       "   'santa',\n",
       "   'daugher',\n",
       "   'fiancee',\n",
       "   'coworker',\n",
       "   'i',\n",
       "   'anniversary',\n",
       "   'member'],\n",
       "  1128,\n",
       "  105),\n",
       " ('B003DZ165W',\n",
       "  338,\n",
       "  268,\n",
       "  ['band',\n",
       "   'strap',\n",
       "   'clip',\n",
       "   'attachment',\n",
       "   'string',\n",
       "   'fastener',\n",
       "   'thingy',\n",
       "   'rope',\n",
       "   'thingie',\n",
       "   'appendage',\n",
       "   'loop',\n",
       "   'attachement'],\n",
       "  1082,\n",
       "  45),\n",
       " ('B003DZ165W',\n",
       "  360,\n",
       "  286,\n",
       "  ['design',\n",
       "   'look',\n",
       "   'style',\n",
       "   'form',\n",
       "   'appearance',\n",
       "   'profile',\n",
       "   'compliment',\n",
       "   'elegance',\n",
       "   'appeal',\n",
       "   'sleekness',\n",
       "   'slimness'],\n",
       "  959,\n",
       "  119),\n",
       " ('B003DZ165W', 363, 289, ['thing', 'kind', 'sort', 'hate', 'plain'], 942, 50)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_clusters_table[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_summary(asin, product_info):\n",
    "    if 'error' not in product_info:\n",
    "        print('ASIN: {}'.format(asin))\n",
    "        \n",
    "        print('# of Positive Sentiments')\n",
    "        feature_sentiments_pos_sorted = sorted([(k,len(v)) for k,v in product_info['feature_sentiments_pos'].items()], key=lambda x: x[1], reverse=True)\n",
    "        pprint(feature_sentiments_pos_sorted[:15])\n",
    "        \n",
    "        print('# of Negative Sentiments')\n",
    "        feature_sentiments_neg_sorted = sorted([(k,len(v)) for k,v in product_info['feature_sentiments_neg'].items()], key=lambda x: x[1], reverse=True)\n",
    "        pprint(feature_sentiments_neg_sorted[:15])\n",
    "        \n",
    "        feature = feature_sentiments_neg_sorted[0][0]\n",
    "        print('FEATURE: {}'.format(feature))\n",
    "        for review_num, words in product_info['feature_words_by_review'].items():\n",
    "            if feature in words:\n",
    "                if product_info['feature_sentiments_by_review'][review_num][feature] < 0:\n",
    "                    print(review_num, product_info['feature_sentiments_by_review'][review_num][feature])\n",
    "                    for sentence_num,review_num_ in enumerate(product_info['review_indices']):\n",
    "                        if review_num == review_num_:\n",
    "                            sentence = product_info['raw_sentences'][sentence_num]\n",
    "                            if feature in [w.lower() for w in sentence.split()]:\n",
    "                                print(sentence)\n",
    "\n",
    "#                print([product_info['raw_sentences'][sentence_num] \\\n",
    "#                       for sentence_num,review_num in enumerate(product_info['review_indices']) \\\n",
    "#                       if feature in product_info['feature_words_by_review'][review_num] ])                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_infos['B00DR0PDNE']['opinion_words_by_review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('B003DZ165W', 4567)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible statistics\n",
    "# # pos sentiments vs # neg sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ADD TO DOUBLE_PROP.PY\n",
    "\n",
    "# snippet table\n",
    "\n",
    "from nltk import word_tokenize\n",
    "asin = 'B000LRMS66'\n",
    "def get_snippet_table(asin, k):\n",
    "    snippets = []\n",
    "    product_info = product_infos[asin]\n",
    "    raw_sentences = product_info['raw_sentences']\n",
    "    review_indices = product_info['review_indices']\n",
    "    top_features_by_count = [feature for feature,cnt in sorted(product_info['features_count'].items(), key=lambda x:x[1], reverse=True)]\n",
    "    top_feature_set = set(top_features_by_count[:k])\n",
    "    for sentence_id, (sentence,review_id) in enumerate(zip(raw_sentences,review_indices)):\n",
    "        for word in word_tokenize(sentence):\n",
    "            word = word.lower()\n",
    "            \n",
    "            if type(k) is int:\n",
    "                if word in top_feature_set:\n",
    "                    polarity = product_info['feature_sentiments_by_review'][review_id]\n",
    "                    snippets.append((asin, word, review_id, sentence_id, sentence, polarity[word]))\n",
    "            elif type(k) is list:\n",
    "                if word in k:\n",
    "                    polarity = product_info['feature_sentiments_by_review'][review_id]\n",
    "                    snippets.append((asin, word, review_id, sentence_id, sentence, polarity[word]))\n",
    "\n",
    "        return snippets\n",
    "\n",
    "# TODO: get_positive/negative_snippets\n",
    "#pprint([(a,b) for a,b in {k:list(filter(lambda w: (product_infos['B00DR0PDNE']['opinion_sentiments'][w] < 0),v)) for k,v in product_infos['B00DR0PDNE']['opinion_words_by_review'].items()}.items() if len(b)>0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin = asins[35][0]\n",
    "snippets = get_snippet_table(asin, 10)\n",
    "positive_snippets = [(asin, word, review_id, sentence_id, sentence, polarity) for asin, word, review_id, sentence_id, sentence, polarity in snippets if polarity > 0]\n",
    "negative_snippets = [(asin, word, review_id, sentence_id, sentence, polarity) for asin, word, review_id, sentence_id, sentence, polarity in snippets if polarity < 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B003DZ165W', 'kindle', 0, 0, 'The lighted Kindle cover works great.', 0),\n",
       " ('B003DZ165W', 'cover', 0, 0, 'The lighted Kindle cover works great.', 1),\n",
       " ('B003DZ165W',\n",
       "  'kindle',\n",
       "  0,\n",
       "  1,\n",
       "  'Protects my Kindle and allows me to read in the dark without a bulky book light.',\n",
       "  0),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  0,\n",
       "  1,\n",
       "  'Protects my Kindle and allows me to read in the dark without a bulky book light.',\n",
       "  -1),\n",
       " ('B003DZ165W',\n",
       "  'leather',\n",
       "  1,\n",
       "  3,\n",
       "  'I purchased a black leather kindle cover with a built in light.',\n",
       "  0),\n",
       " ('B003DZ165W',\n",
       "  'kindle',\n",
       "  1,\n",
       "  3,\n",
       "  'I purchased a black leather kindle cover with a built in light.',\n",
       "  0),\n",
       " ('B003DZ165W',\n",
       "  'cover',\n",
       "  1,\n",
       "  3,\n",
       "  'I purchased a black leather kindle cover with a built in light.',\n",
       "  1),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  1,\n",
       "  3,\n",
       "  'I purchased a black leather kindle cover with a built in light.',\n",
       "  0),\n",
       " ('B003DZ165W', 'cover', 2, 5, 'This is a really nice cover.', 1),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  2,\n",
       "  7,\n",
       "  'The light is perfect - I use it on planes as it is a much better light than the overhead light.',\n",
       "  1),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  2,\n",
       "  7,\n",
       "  'The light is perfect - I use it on planes as it is a much better light than the overhead light.',\n",
       "  1),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  2,\n",
       "  7,\n",
       "  'The light is perfect - I use it on planes as it is a much better light than the overhead light.',\n",
       "  1),\n",
       " ('B003DZ165W', 'kindle', 3, 9, 'If, you have a kindle, get the cover.', 0),\n",
       " ('B003DZ165W', 'cover', 3, 9, 'If, you have a kindle, get the cover.', 0),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  3,\n",
       "  10,\n",
       "  'The retractable light is a great plus for reading in dimmed lighting!',\n",
       "  1),\n",
       " ('B003DZ165W',\n",
       "  'kindle',\n",
       "  4,\n",
       "  11,\n",
       "  'It is a nice size and it protects the Kindle well.',\n",
       "  0),\n",
       " ('B003DZ165W',\n",
       "  'light',\n",
       "  4,\n",
       "  12,\n",
       "  'The light is great and works off of the Kindle battery.',\n",
       "  1),\n",
       " ('B003DZ165W',\n",
       "  'kindle',\n",
       "  4,\n",
       "  12,\n",
       "  'The light is great and works off of the Kindle battery.',\n",
       "  0),\n",
       " ('B003DZ165W',\n",
       "  'kindle',\n",
       "  5,\n",
       "  14,\n",
       "  'It protects my Kindle, is easy to manage when I read with one hand, folds back just fine.',\n",
       "  0),\n",
       " ('B003DZ165W',\n",
       "  'case',\n",
       "  5,\n",
       "  15,\n",
       "  \"It looks good (much nicer than my husband's vinyl case that just holds the Kindle in with cheap plastic clips...).\",\n",
       "  0)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
