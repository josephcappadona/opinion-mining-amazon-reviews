{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from pprint import pprint\n",
    "\n",
    "config = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"database\": \"senior_design\"\n",
    "}\n",
    "connection = mysql.connector.connect(**config)\n",
    "cursor = connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-06b8ee63bc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT distinct asin, COUNT(asin) AS count FROM review GROUP BY asin ORDER BY count DESC\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0masins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0masin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0masins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W0212\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mServerCmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36m_send_cmd\u001b[0;34m(self, command, argument, packet_number, packet, expect_response, compressed_packet_number)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpect_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend_empty_packet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mysql/connector/network.py\u001b[0m in \u001b[0;36mrecv_plain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mpacket_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mpacket_len\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpacket_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2013\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = \"SELECT distinct asin, COUNT(asin) AS count FROM review GROUP BY asin ORDER BY count DESC\"\n",
    "cursor.execute(query)\n",
    "asins = []\n",
    "for asin, count in cursor:\n",
    "    asins.append((asin,count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(asins[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reviews(asin):\n",
    "    query = \"SELECT review_text FROM review WHERE asin = '{}'\".format(asin)\n",
    "    cursor.execute(query)\n",
    "    reviews = []\n",
    "    for (review_text) in cursor:\n",
    "        reviews.append(review_text[0])\n",
    "    print(\"# reviews: {}\".format(len(reviews)))\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# reviews: 720\n"
     ]
    }
   ],
   "source": [
    "reviews = get_all_reviews(\"B00004ZC8Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lexicon = {\"good\", \"great\", \"better\", \"excellent\", \"best\", \"easy\", \"nice\", \"simple\", \"clear\", \"strong\", \n",
    "                    \"perfect\", \"comfortable\", \"friendly\", \"solid\", \"precise\", \"awesome\", \"amazing\", \"bright\", \"vibrant\",\n",
    "                    \"fantastic\", \"vibrant\", \"realistic\", \"stunning\", \"superior\", \"super\", \"rich\", \"exceptional\",\n",
    "                    \"impressive\", \"ideal\"}\n",
    "negative_lexicon = {\"poor\", \"old\", \"bad\", \"weak\", \"annoying\", \"defective\", \"horrible\", \"buggy\", \"worst\", \"mediocre\",\n",
    "                    \"difficult\", \"unstable\", \"inferior\", \"lousy\", \"complicated\", \"useless\", \"unreliable\", \"sloppy\",\n",
    "                    \"strange\", \"weird\", \"malfunctioning\", \"miserable\", \"terrible\", \"misleading\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "# Start the CoreNLP server with:\n",
    "# java -mx4g -cp \"./CoreNLP/*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "#     (on my Mac, java8 bin located at /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java)\n",
    "nlp = CoreNLPDependencyParser(url=\"http://localhost:9000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# input: parsed_sentence, cumulative information dictionaries (FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count)\n",
    "# output: extracted dependency features\n",
    "def extract_relevant_dependencies(parsed_sentence, FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count):\n",
    "    extracted_sentence = []\n",
    "    for (gov, gov_pos), dependency, (dep, dep_pos) in parsed_sentence.triples():\n",
    "        if not gov.isalpha() or not dep.isalpha():\n",
    "            continue\n",
    "        gov = gov.lower()\n",
    "        dep = dep.lower()\n",
    "        if dependency == \"nsubj\" and dep_pos == \"NN\":\n",
    "            OF_dict[gov] = dep\n",
    "            FO_dict[dep] = gov\n",
    "            features_count[dep] += 1\n",
    "            opinions_count[gov] += 1\n",
    "        elif dependency == \"amod\" and gov_pos == \"NN\":\n",
    "            OF_dict[dep] = gov\n",
    "            FO_dict[gov] = dep\n",
    "            opinions_count[dep] += 1\n",
    "            features_count[gov] += 1\n",
    "        elif dependency == \"conj\":\n",
    "            if gov_pos == \"JJ\" and dep_pos == \"JJ\":\n",
    "                OO_dict[gov].append(dep)\n",
    "                OO_dict[dep].append(gov)\n",
    "                opinions_count[gov] += 1\n",
    "                opinions_count[dep] += 1\n",
    "            elif gov_pos == \"NN\" and dep_pos == \"NN\":\n",
    "                FF_dict[gov].append(dep)\n",
    "                FF_dict[dep].append(gov)\n",
    "                features_count[gov] += 1\n",
    "                features_count[dep] += 1\n",
    "        extracted_sentence.append(((gov, gov_pos), dependency, (dep, dep_pos)))\n",
    "    #parsed_sentences.append(extracted_sentence)\n",
    "    return extracted_sentence\n",
    "\n",
    "\n",
    "# input: all_review_info, cumulative information dictionaries\n",
    "# output: new_features, new_opinions\n",
    "def double_propagation_iterate(all_review_info,\n",
    "                               features,\n",
    "                               feature_words_by_review,\n",
    "                               feature_sentiments_by_review,\n",
    "                               feature_sentiments_cumulative,\n",
    "                               feature_sentiments_pos,\n",
    "                               feature_sentiments_neg,\n",
    "                               opinions,\n",
    "                               opinion_words_by_review,\n",
    "                               opinion_sentiments):\n",
    "    new_opinions = set()\n",
    "    new_features = set()\n",
    "\n",
    "    for index, info in all_review_info.items():\n",
    "        feature_sentiments_by_review[index] = defaultdict(int)\n",
    "\n",
    "        for opinion, feature in info['OF_dict'].items():\n",
    "            if opinion in opinions:\n",
    "                if feature not in features:\n",
    "                    new_features.add(feature)\n",
    "\n",
    "                if feature not in feature_words_by_review[index]:\n",
    "                    feature_words_by_review[index].add(feature)\n",
    "\n",
    "                    # target takes polarity of modifying opinion word\n",
    "                    feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                    # add to target's cumulative sentiment score\n",
    "                    feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                    if opinion_sentiments[opinion] > 0:\n",
    "                        feature_sentiments_pos[feature].append(info['index'])\n",
    "                    elif opinion_sentiments[opinion] < 0:\n",
    "                        feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "                # have we seen this opinion word in this review?\n",
    "                if opinion not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "        for opinion1, related in info['OO_dict'].items():\n",
    "            if opinion1 in opinions:\n",
    "                for opinion in related:\n",
    "                    if opinion not in opinions:\n",
    "                        new_opinions.add(opinion)\n",
    "                        opinion_sentiments[opinion] = opinion_sentiments[opinion1]\n",
    "\n",
    "                    # have we seen this opinion word in this review?\n",
    "                    if opinion not in opinion_words_by_review[index]:\n",
    "                        opinion_words_by_review[index].add(opinion)\n",
    "                        info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "                # have we seen this opinion word in this review?\n",
    "                if opinion1 not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion1)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion1]\n",
    "\n",
    "        for feature, opinion in info['FO_dict'].items():\n",
    "            if feature in features:\n",
    "                if opinion not in opinions:\n",
    "                    new_opinions.add(opinion)\n",
    "\n",
    "                    # if target has sentiment in current review\n",
    "                    if feature in feature_words_by_review[index]:\n",
    "                        # then opinion takes polarity of target (Homogenous Rule)\n",
    "                        opinion_sentiments[opinion] = feature_sentiments_by_review[index][feature]\n",
    "                    else:\n",
    "                        # else target is from another review\n",
    "                        # opinion takes cumulative sentiment of entire review (Intra-review Rule)\n",
    "                        try:\n",
    "                            cumulative_polarity = int(info['cumulative_polarity'] / abs(info['cumulative_polarity']))\n",
    "                        except ZeroDivisionError:\n",
    "                            cumulative_polarity = 0\n",
    "                        opinion_sentiments[opinion] = cumulative_polarity\n",
    "\n",
    "                        # also apply that polarity to the feature (should we do this?)\n",
    "                        feature_words_by_review[index].add(feature)\n",
    "                        feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                        # add to target's cumulative sentiment\n",
    "                        feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                        if opinion_sentiments[opinion] > 0:\n",
    "                            feature_sentiments_pos[feature].append(info['index'])\n",
    "                        elif opinion_sentiments[opinion] < 0:\n",
    "                            feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "                if opinion not in opinion_words_by_review[index]:\n",
    "                    opinion_words_by_review[index].add(opinion)\n",
    "                    info['cumulative_polarity'] += opinion_sentiments[opinion]\n",
    "\n",
    "                if feature not in feature_sentiments_by_review[index]:\n",
    "                    feature_words_by_review[index].add(feature)\n",
    "                    feature_sentiments_by_review[index][feature] = opinion_sentiments[opinion]\n",
    "                    # add to target's cumulative sentiment\n",
    "                    feature_sentiments_cumulative[feature] += opinion_sentiments[opinion]\n",
    "                    if opinion_sentiments[opinion] > 0:\n",
    "                        feature_sentiments_pos[feature].append(info['index'])\n",
    "                    elif opinion_sentiments[opinion] < 0:\n",
    "                        feature_sentiments_neg[feature].append(info['index'])\n",
    "\n",
    "        for feature1, related in info['FF_dict'].items():\n",
    "            if feature1 in features and feature1 in feature_sentiments_by_review[index]:\n",
    "                for feature in related:\n",
    "                    if feature not in features:\n",
    "                        new_features.add(feature)\n",
    "\n",
    "                    # have we seen this target word in this review?\n",
    "                    if feature not in feature_words_by_review[index]:\n",
    "                        feature_words_by_review[index].add(feature)\n",
    "\n",
    "                        # Homogenous Rule\n",
    "                        feature_sentiments_by_review[index][feature] = feature_sentiments_by_review[index][feature1]\n",
    "                        feature_sentiments_cumulative[feature] += feature_sentiments_by_review[index][feature]\n",
    "                        if feature_sentiments_by_review[index][feature] > 0:\n",
    "                            feature_sentiments_pos[feature].append(info['index'])\n",
    "                        elif feature_sentiments_by_review[index][feature] < 0:\n",
    "                            feature_sentiments_neg[feature].append(info['index'])\n",
    "    return new_features, new_opinions\n",
    "\n",
    "\n",
    "# input: list of review texts\n",
    "# output: all features, expanded opinion lexicon\n",
    "def extract_features_opinions(reviews):\n",
    "    features = set()\n",
    "    features_count = defaultdict(int)\n",
    "    opinions = positive_lexicon.union(negative_lexicon)\n",
    "    opinions_count = defaultdict(int)\n",
    "    \n",
    "    raw_sentences = []\n",
    "    parsed_sentences = []\n",
    "    parses = []\n",
    "    review_indices = []\n",
    "    review_info = {} # store info about deps on per review basis\n",
    "    for i, review in enumerate(reviews):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        OF_dict = {}\n",
    "        FO_dict = {}\n",
    "        OO_dict = defaultdict(list)\n",
    "        FF_dict = defaultdict(list)\n",
    "        \n",
    "        raw_sentences.extend(sent_tokenize(review))\n",
    "        parse = nlp.parse_text(review)\n",
    "        parses.append(parse)\n",
    "        for sentence in parse:\n",
    "            # extract relevant dependency information\n",
    "            extracted_sentence = extract_relevant_dependencies(sentence, FO_dict, OF_dict, FF_dict, OO_dict, features_count, opinions_count)\n",
    "            \n",
    "            review_indices.append(i)\n",
    "            parsed_sentences.append(extracted_sentence)\n",
    "\n",
    "        review_info[i] = { 'index' : i,\n",
    "                           'OF_dict' : OF_dict,\n",
    "                           'FO_dict' : FO_dict,\n",
    "                           'OO_dict' : OO_dict,\n",
    "                           'FF_dict' : FF_dict,\n",
    "                           'cumulative_polarity' : 0 }\n",
    "\n",
    "    # instantiate cumulative data structures\n",
    "    i = 0\n",
    "    feature_sentiments_by_review = defaultdict(dict) # same sentiment for target words within review (this is an assumption [Observation 1])\n",
    "    feature_sentiments_cumulative = defaultdict(int)\n",
    "    feature_sentiments_pos = defaultdict(list) # keep track of the review indices that contributed negative sentiments toward each feature\n",
    "    feature_sentiments_neg = defaultdict(list) # keep track of the review indices that contributed negative sentiments toward each feature\n",
    "    feature_words_by_review = defaultdict(set) # keep track of the feature words in each review\n",
    "    opinion_words_by_review = defaultdict(set) # keep track of the opinion words in each review\n",
    "    opinion_sentiments = {} # same sentiment for opinion words throughout the corpus (this is an assumption [Observation 2])\n",
    "    opinion_sentiments.update({op:(1 if op in positive_lexicon else -1) for op in opinions})\n",
    "\n",
    "    while (True):\n",
    "        print(\"DP Iteration: {}\".format(i))\n",
    "        i += 1\n",
    "\n",
    "        # double propagation step\n",
    "        new_features, \\\n",
    "        new_opinions = double_propagation_iterate(review_info,\n",
    "                                                  features,\n",
    "                                                  feature_words_by_review,\n",
    "                                                  feature_sentiments_by_review,\n",
    "                                                  feature_sentiments_cumulative,\n",
    "                                                  feature_sentiments_pos,\n",
    "                                                  feature_sentiments_neg,\n",
    "                                                  opinions,\n",
    "                                                  opinion_words_by_review,\n",
    "                                                  opinion_sentiments)\n",
    "        \n",
    "        features = features.union(new_features)\n",
    "        opinions = opinions.union(new_opinions)\n",
    "        if len(new_opinions) == 0 and len(new_features) == 0:\n",
    "            break\n",
    "\n",
    "    res = (features,\n",
    "           features_count,\n",
    "           opinions,\n",
    "           opinions_count,\n",
    "           raw_sentences,\n",
    "           parsed_sentences,\n",
    "           review_indices,\n",
    "           feature_sentiments_by_review,\n",
    "           feature_words_by_review,\n",
    "           feature_sentiments_cumulative,\n",
    "           feature_sentiments_pos,\n",
    "           feature_sentiments_neg,\n",
    "           opinion_words_by_review,\n",
    "           opinion_sentiments)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product quality clustering\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "feature_to_class = pickle.load(open(\"./clustering/results/clean-classes.pkl\", \"rb\"))\n",
    "\n",
    "def get_sorted_classes(features_by_count):\n",
    "    frequent_features = [(f, cnt) for f, cnt in features_by_count if cnt >= 5]\n",
    "    features_by_class = dict()\n",
    "    not_found = set()\n",
    "\n",
    "    # features_by_class is a dict from class number -> [feature list, total count]\n",
    "    for feature, cnt in frequent_features:\n",
    "        if feature not in feature_to_class:\n",
    "            not_found.add(feature)\n",
    "            continue\n",
    "        class_num = feature_to_class[feature]\n",
    "        if class_num not in features_by_class:\n",
    "            features_by_class[class_num] = [[], 0]\n",
    "        features_by_class[class_num][0].append(feature)\n",
    "        features_by_class[class_num][1] += cnt\n",
    "\n",
    "    sorted_classes = sorted(features_by_class.values(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Not found in any cluster: \" + str(not_found))\n",
    "    return sorted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "DP Iteration: 0\n",
      "DP Iteration: 1\n",
      "DP Iteration: 2\n",
      "DP Iteration: 3\n",
      "DP Iteration: 4\n",
      "DP Iteration: 5\n",
      "DP Iteration: 6\n",
      "DP Iteration: 7\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "features, \\\n",
    "features_count, \\\n",
    "opinions, \\\n",
    "opinions_count, \\\n",
    "raw_sentences, \\\n",
    "parsed_sentences, \\\n",
    "review_indices, \\\n",
    "feature_sentiments_by_review, \\\n",
    "feature_words_by_review, \\\n",
    "feature_sentiments_cumulative, \\\n",
    "feature_sentiments_pos, \\\n",
    "feature_sentiments_neg, \\\n",
    "opinion_words_by_review, \\\n",
    "opinion_sentiments = extract_features_opinions(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature words, occurrences:\n",
      "[('filter', 344),\n",
      " ('polarizer', 171),\n",
      " ('lens', 91),\n",
      " ('quality', 77),\n",
      " ('price', 73),\n",
      " ('product', 57),\n",
      " ('sky', 52),\n",
      " ('glass', 40),\n",
      " ('effect', 38),\n",
      " ('job', 35),\n",
      " ('time', 28),\n",
      " ('light', 27),\n",
      " ('ring', 26),\n",
      " ('glare', 24),\n",
      " ('fit', 22),\n",
      " ('day', 21),\n",
      " ('value', 20),\n",
      " ('camera', 20),\n",
      " ('water', 19),\n",
      " ('difference', 18),\n",
      " ('contrast', 17),\n",
      " ('thing', 17),\n",
      " ('sun', 17),\n",
      " ('way', 16),\n",
      " ('problem', 15),\n",
      " ('brand', 15),\n",
      " ('part', 15),\n",
      " ('item', 15),\n",
      " ('color', 15),\n",
      " ('size', 14),\n",
      " ('photography', 13),\n",
      " ('use', 12),\n",
      " ('case', 12),\n",
      " ('reflection', 12),\n",
      " ('condition', 11),\n",
      " ('nothing', 11),\n",
      " ('cap', 10),\n",
      " ('issue', 10),\n",
      " ('box', 9),\n",
      " ('addition', 9),\n",
      " ('sunlight', 9),\n",
      " ('angle', 9),\n",
      " ('rotation', 9),\n",
      " ('work', 9),\n",
      " ('mm', 9),\n",
      " ('construction', 9),\n",
      " ('look', 8),\n",
      " ('saturation', 8),\n",
      " ('delivery', 7),\n",
      " ('blue', 7),\n",
      " ('point', 7),\n",
      " ('loss', 7),\n",
      " ('experience', 7),\n",
      " ('shooting', 7),\n",
      " ('piece', 7),\n",
      " ('shipping', 7),\n",
      " ('challenge', 7),\n",
      " ('right', 7),\n",
      " ('money', 7),\n",
      " ('clarity', 7),\n",
      " ('buy', 7),\n",
      " ('purchase', 7),\n",
      " ('thread', 6),\n",
      " ('something', 6),\n",
      " ('side', 6),\n",
      " ('everything', 6),\n",
      " ('reason', 6),\n",
      " ('picture', 6),\n",
      " ('direction', 6),\n",
      " ('user', 6),\n",
      " ('action', 6),\n",
      " ('haze', 6),\n",
      " ('image', 6),\n",
      " ('tiffen', 6),\n",
      " ('movement', 6),\n",
      " ('ger', 6),\n",
      " ('packaging', 5),\n",
      " ('element', 5),\n",
      " ('disappointment', 5),\n",
      " ('cpl', 5),\n",
      " ('trip', 5),\n",
      " ('equipment', 5),\n",
      " ('function', 5),\n",
      " ('speed', 5),\n",
      " ('result', 5),\n",
      " ('lot', 5),\n",
      " ('area', 4),\n",
      " ('dust', 4),\n",
      " ('grime', 4),\n",
      " ('polarization', 4),\n",
      " ('amount', 4),\n",
      " ('vignette', 4),\n",
      " ('photo', 4),\n",
      " ('fan', 4),\n",
      " ('purpose', 4),\n",
      " ('performance', 4),\n",
      " ('air', 4),\n",
      " ('shot', 4),\n",
      " ('depth', 4),\n",
      " ('resistance', 4),\n",
      " ('end', 4),\n",
      " ('friend', 4),\n",
      " ('tool', 4),\n",
      " ('vignetting', 4),\n",
      " ('material', 4),\n",
      " ('choice', 4),\n",
      " ('change', 4),\n",
      " ('eye', 4),\n",
      " ('deal', 4),\n",
      " ('performer', 3),\n",
      " ('cover', 3),\n",
      " ('space', 3),\n",
      " ('dirt', 3),\n",
      " ('inspection', 3),\n",
      " ('source', 3),\n",
      " ('warranty', 3),\n",
      " ('subject', 3),\n",
      " ('anything', 3),\n",
      " ('exposure', 3),\n",
      " ('foliage', 3),\n",
      " ('model', 3),\n",
      " ('budget', 3),\n",
      " ('l', 3),\n",
      " ('pricing', 3),\n",
      " ('cp', 3),\n",
      " ('twist', 3),\n",
      " ('landscape', 3),\n",
      " ('circle', 3),\n",
      " ('lense', 3),\n",
      " ('ocean', 3),\n",
      " ('bit', 3),\n",
      " ('uv', 3),\n",
      " ('lubricant', 3),\n",
      " ('flare', 3),\n",
      " ('tint', 3),\n",
      " ('ca', 3),\n",
      " ('mechanism', 3),\n",
      " ('t', 3),\n",
      " ('daylight', 3),\n",
      " ('version', 3),\n",
      " ('fun', 3),\n",
      " ('distortion', 3),\n",
      " ('situation', 3),\n",
      " ('production', 3),\n",
      " ('weather', 3),\n",
      " ('someone', 3),\n",
      " ('half', 3),\n",
      " ('style', 3),\n",
      " ('system', 3),\n",
      " ('noise', 2),\n",
      " ('shipment', 2),\n",
      " ('order', 2),\n",
      " ('len', 2),\n",
      " ('explanation', 2),\n",
      " ('couple', 2),\n",
      " ('store', 2),\n",
      " ('lighting', 2),\n",
      " ('effort', 2),\n",
      " ('mark', 2),\n",
      " ('practice', 2),\n",
      " ('position', 2),\n",
      " ('polariser', 2),\n",
      " ('background', 2),\n",
      " ('supplier', 2),\n",
      " ('opportunity', 2),\n",
      " ('meter', 2),\n",
      " ('coating', 2),\n",
      " ('faith', 2),\n",
      " ('rim', 2),\n",
      " ('profile', 2),\n",
      " ('hand', 2),\n",
      " ('shape', 2),\n",
      " ('bang', 2),\n",
      " ('ability', 2),\n",
      " ('help', 2),\n",
      " ('photograph', 2),\n",
      " ('cloth', 2),\n",
      " ('splotch', 2),\n",
      " ('design', 2),\n",
      " ('degree', 2),\n",
      " ('transmission', 2),\n",
      " ('level', 2),\n",
      " ('viewfinder', 2),\n",
      " ('film', 2),\n",
      " ('cost', 2),\n",
      " ('dial', 2),\n",
      " ('beach', 2),\n",
      " ('max', 2),\n",
      " ('feature', 2),\n",
      " ('shade', 2),\n",
      " ('summer', 2),\n",
      " ('son', 2),\n",
      " ('tone', 2),\n",
      " ('band', 2),\n",
      " ('shop', 2),\n",
      " ('service', 2),\n",
      " ('stuff', 2),\n",
      " ('banding', 2),\n",
      " ('threading', 2),\n",
      " ('trouble', 2),\n",
      " ('adapter', 2),\n",
      " ('review', 2),\n",
      " ('solution', 2),\n",
      " ('revolution', 2),\n",
      " ('company', 2),\n",
      " ('advice', 2),\n",
      " ('flaw', 2),\n",
      " ('spot', 2),\n",
      " ('deliverydont', 2),\n",
      " ('metal', 2),\n",
      " ('screen', 2),\n",
      " ('bag', 2),\n",
      " ('husband', 2),\n",
      " ('device', 2),\n",
      " ('maximum', 2),\n",
      " ('stop', 2),\n",
      " ('location', 2),\n",
      " ('cheap', 2),\n",
      " ('one', 2),\n",
      " ('od', 2),\n",
      " ('need', 2),\n",
      " ('tinging', 2),\n",
      " ('appearance', 2),\n",
      " ('downside', 2),\n",
      " ('pressure', 2),\n",
      " ('benefit', 2),\n",
      " ('portion', 2),\n",
      " ('environment', 2),\n",
      " ('surface', 2),\n",
      " ('processing', 2),\n",
      " ('hoya', 2),\n",
      " ('puddle', 2),\n",
      " ('length', 2),\n",
      " ('complaint', 2),\n",
      " ('scratch', 1),\n",
      " ('paint', 1),\n",
      " ('strip', 1),\n",
      " ('evidence', 1),\n",
      " ('layer', 1),\n",
      " ('package', 1),\n",
      " ('enough', 1),\n",
      " ('range', 1),\n",
      " ('return', 1),\n",
      " ('waste', 1),\n",
      " ('copy', 1),\n",
      " ('warehouse', 1),\n",
      " ('padding', 1),\n",
      " ('barrel', 1),\n",
      " ('wish', 1),\n",
      " ('coloring', 1),\n",
      " ('hate', 1),\n",
      " ('number', 1),\n",
      " ('nature', 1),\n",
      " ('mortgage', 1),\n",
      " ('research', 1),\n",
      " ('father', 1),\n",
      " ('pro', 1),\n",
      " ('unit', 1),\n",
      " ('pair', 1),\n",
      " ('wheel', 1),\n",
      " ('checap', 1),\n",
      " ('novice', 1),\n",
      " ('hour', 1),\n",
      " ('punch', 1),\n",
      " ('ethanol', 1),\n",
      " ('boost', 1),\n",
      " ('vendor', 1),\n",
      " ('exception', 1),\n",
      " ('pit', 1),\n",
      " ('hype', 1),\n",
      " ('city', 1),\n",
      " ('disassembly', 1),\n",
      " ('plate', 1),\n",
      " ('poster', 1),\n",
      " ('person', 1),\n",
      " ('hood', 1),\n",
      " ('testing', 1),\n",
      " ('improvement', 1),\n",
      " ('noon', 1),\n",
      " ('smooth', 1),\n",
      " ('proof', 1),\n",
      " ('focus', 1),\n",
      " ('trade', 1),\n",
      " ('valley', 1),\n",
      " ('margin', 1),\n",
      " ('operation', 1),\n",
      " ('owner', 1),\n",
      " ('contstruction', 1),\n",
      " ('sensor', 1),\n",
      " ('factor', 1),\n",
      " ('cut', 1),\n",
      " ('compactness', 1),\n",
      " ('wallet', 1),\n",
      " ('kit', 1),\n",
      " ('description', 1),\n",
      " ('hilltop', 1),\n",
      " ('disc', 1),\n",
      " ('protection', 1),\n",
      " ('pin', 1),\n",
      " ('impact', 1),\n",
      " ('knob', 1),\n",
      " ('actuall', 1),\n",
      " ('setting', 1),\n",
      " ('section', 1),\n",
      " ('jiggle', 1),\n",
      " ('match', 1),\n",
      " ('graphite', 1),\n",
      " ('frame', 1),\n",
      " ('run', 1),\n",
      " ('life', 1),\n",
      " ('tip', 1),\n",
      " ('opinion', 1),\n",
      " ('support', 1),\n",
      " ('charge', 1),\n",
      " ('dslr', 1),\n",
      " ('enthusiast', 1),\n",
      " ('fine', 1),\n",
      " ('dryer', 1),\n",
      " ('power', 1),\n",
      " ('sign', 1),\n",
      " ('credit', 1),\n",
      " ('dealer', 1),\n",
      " ('reference', 1),\n",
      " ('im', 1),\n",
      " ('advertising', 1),\n",
      " ('degradation', 1),\n",
      " ('brother', 1),\n",
      " ('asset', 1),\n",
      " ('news', 1),\n",
      " ('combo', 1),\n",
      " ('ease', 1),\n",
      " ('overlay', 1),\n",
      " ('triffen', 1),\n",
      " ('example', 1),\n",
      " ('hv', 1),\n",
      " ('iso', 1),\n",
      " ('policy', 1),\n",
      " ('abrasion', 1),\n",
      " ('vinetting', 1),\n",
      " ('sand', 1),\n",
      " ('possibility', 1),\n",
      " ('cross', 1),\n",
      " ('harm', 1),\n",
      " ('suite', 1),\n",
      " ('didnt', 1),\n",
      " ('rest', 1),\n",
      " ('ll', 1),\n",
      " ('market', 1),\n",
      " ('unlessyou', 1),\n",
      " ('sea', 1),\n",
      " ('darkness', 1),\n",
      " ('honeymoon', 1),\n",
      " ('success', 1),\n",
      " ('fault', 1),\n",
      " ('school', 1),\n",
      " ('protector', 1),\n",
      " ('fliter', 1),\n",
      " ('cord', 1),\n",
      " ('reduction', 1),\n",
      " ('container', 1),\n",
      " ('filtre', 1),\n",
      " ('gift', 1),\n",
      " ('framing', 1),\n",
      " ('regard', 1),\n",
      " ('machining', 1),\n",
      " ('discoloration', 1),\n",
      " ('meaning', 1),\n",
      " ('pol', 1),\n",
      " ('attachment', 1),\n",
      " ('wife', 1),\n",
      " ('taker', 1),\n",
      " ('inch', 1),\n",
      " ('minimum', 1),\n",
      " ('front', 1),\n",
      " ('shutter', 1),\n",
      " ('plastic', 1),\n",
      " ('boon', 1),\n",
      " ('foreground', 1),\n",
      " ('filer', 1),\n",
      " ('aberration', 1),\n",
      " ('guide', 1),\n",
      " ('move', 1),\n",
      " ('daughter', 1),\n",
      " ('mk', 1),\n",
      " ('diffrence', 1),\n",
      " ('winter', 1),\n",
      " ('pouch', 1),\n",
      " ('polvopor', 1),\n",
      " ('pointer', 1),\n",
      " ('thanks', 1),\n",
      " ('balance', 1),\n",
      " ('care', 1),\n",
      " ('humidity', 1),\n",
      " ('upside', 1),\n",
      " ('buying', 1),\n",
      " ('middle', 1),\n",
      " ('union', 1),\n",
      " ('plain', 1),\n",
      " ('accessory', 1),\n",
      " ('nd', 1),\n",
      " ('quitre', 1),\n",
      " ('sight', 1),\n",
      " ('aperture', 1),\n",
      " ('wiil', 1),\n",
      " ('set', 1),\n",
      " ('impression', 1),\n",
      " ('art', 1),\n",
      " ('reputation', 1),\n",
      " ('coverage', 1),\n",
      " ('praise', 1),\n",
      " ('name', 1),\n",
      " ('vibrancy', 1),\n",
      " ('finish', 1),\n",
      " ('producer', 1),\n",
      " ('variation', 1),\n",
      " ('expanse', 1),\n",
      " ('texture', 1),\n",
      " ('photoshop', 1),\n",
      " ('id', 1),\n",
      " ('grade', 1),\n",
      " ('step', 1),\n",
      " ('ratio', 1),\n",
      " ('sidewalk', 1),\n",
      " ('idea', 1),\n",
      " ('grip', 1),\n",
      " ('blurb', 1),\n",
      " ('anyone', 1),\n",
      " ('scene', 1),\n",
      " ('maker', 1),\n",
      " ('contruction', 1),\n",
      " ('self', 1),\n",
      " ('fitter', 1),\n",
      " ('luck', 1),\n",
      " ('turn', 1),\n",
      " ('month', 1),\n",
      " ('junk', 1),\n",
      " ('touch', 1),\n",
      " ('steam', 1),\n",
      " ('thumbprint', 1),\n",
      " ('factory', 1),\n",
      " ('amazon', 1),\n",
      " ('darkening', 1),\n",
      " ('monitor', 1),\n",
      " ('xti', 1),\n",
      " ('usm', 1),\n",
      " ('shoot', 1),\n",
      " ('boy', 1),\n",
      " ('brightness', 1),\n",
      " ('everyone', 1),\n",
      " ('shoting', 1),\n",
      " ('test', 1),\n",
      " ('none', 1),\n",
      " ('fingerprint', 1),\n",
      " ('flash', 1),\n",
      " ('love', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature words, occurrences:\")\n",
    "features_by_count = sorted(features_count.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(features_by_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature clusters:\n",
      "Not found in any cluster: {'issue', 'clarity', 'problem', 'ger', 'work', 'photography', 'lot', 'equipment', 'difference', 'reason', 'day', 'nothing', 'product', 'right', 'everything', 'disappointment', 'thing', 'side', 'trip', 'result', 'use', 'something', 'job', 'addition'}\n",
      "[[['filter', 'polarizer', 'tiffen', 'element', 'cpl'], 531],\n",
      " [['lens', 'shooting'], 98],\n",
      " [['quality', 'value'], 97],\n",
      " [['price', 'money', 'buy'], 87],\n",
      " [['glare', 'sun', 'reflection', 'sunlight'], 62],\n",
      " [['sky'], 52],\n",
      " [['effect', 'haze'], 44],\n",
      " [['glass'], 40],\n",
      " [['contrast', 'saturation', 'point', 'image'], 38],\n",
      " [['ring', 'cap'], 36],\n",
      " [['item', 'delivery', 'shipping', 'purchase'], 36],\n",
      " [['way', 'angle', 'rotation'], 34],\n",
      " [['time'], 28],\n",
      " [['light'], 27],\n",
      " [['fit'], 22],\n",
      " [['part', 'piece'], 22],\n",
      " [['camera'], 20],\n",
      " [['water'], 19],\n",
      " [['brand'], 15],\n",
      " [['color'], 15],\n",
      " [['size'], 14],\n",
      " [['box', 'packaging'], 14],\n",
      " [['case'], 12],\n",
      " [['condition'], 11],\n",
      " [['mm'], 9],\n",
      " [['construction'], 9],\n",
      " [['look'], 8],\n",
      " [['blue'], 7],\n",
      " [['loss'], 7],\n",
      " [['experience'], 7],\n",
      " [['challenge'], 7],\n",
      " [['thread'], 6],\n",
      " [['picture'], 6],\n",
      " [['direction'], 6],\n",
      " [['user'], 6],\n",
      " [['action'], 6],\n",
      " [['movement'], 6],\n",
      " [['function'], 5],\n",
      " [['speed'], 5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature clusters:\")\n",
    "sorted_classes = get_sorted_classes(features_by_count)\n",
    "pprint(sorted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion words, occurrences:\n",
      "[('good', 35),\n",
      " ('great', 25),\n",
      " ('usb', 22),\n",
      " ('little', 21),\n",
      " ('external', 19),\n",
      " ('is', 19),\n",
      " ('small', 18),\n",
      " ('better', 15),\n",
      " ('easy', 15),\n",
      " ('nice', 15),\n",
      " ('other', 13),\n",
      " ('only', 12),\n",
      " ('video', 12),\n",
      " ('same', 11),\n",
      " ('more', 11),\n",
      " ('quick', 11),\n",
      " ('first', 11),\n",
      " ('old', 10),\n",
      " ('high', 10),\n",
      " ('low', 9),\n",
      " ('short', 9),\n",
      " ('clear', 9),\n",
      " ('mic', 8),\n",
      " ('sound', 8),\n",
      " ('hard', 8),\n",
      " ('excellent', 7),\n",
      " ('bad', 7),\n",
      " ('sensitive', 7),\n",
      " ('last', 7),\n",
      " ('wide', 7),\n",
      " ('was', 6),\n",
      " ('best', 6),\n",
      " ('full', 6),\n",
      " ('awesome', 6),\n",
      " ('creative', 6),\n",
      " ('digital', 6),\n",
      " ('fine', 6),\n",
      " ('new', 5),\n",
      " ('available', 5),\n",
      " ('poor', 5),\n",
      " ('fantastic', 5),\n",
      " ('handy', 5),\n",
      " ('have', 5),\n",
      " ('seems', 5),\n",
      " ('internal', 5),\n",
      " ('included', 5),\n",
      " ('perfect', 5),\n",
      " ('next', 4),\n",
      " ('extra', 4),\n",
      " ('inexpensive', 4),\n",
      " ('right', 4),\n",
      " ('works', 4),\n",
      " ('impressed', 4),\n",
      " ('removable', 4),\n",
      " ('audio', 4),\n",
      " ('big', 4),\n",
      " ('plus', 3),\n",
      " ('defective', 3),\n",
      " ('recording', 3),\n",
      " ('lightweight', 3),\n",
      " ('entire', 3),\n",
      " ('tiny', 3),\n",
      " ('light', 3),\n",
      " ('acceptable', 3),\n",
      " ('huge', 3),\n",
      " ('work', 3),\n",
      " ('cool', 3),\n",
      " ('professional', 3),\n",
      " ('power', 3),\n",
      " ('turn', 3),\n",
      " ('higher', 3),\n",
      " ('has', 3),\n",
      " ('surprised', 3),\n",
      " ('dedicated', 3),\n",
      " ('similar', 3),\n",
      " ('superb', 3),\n",
      " ('crisp', 3),\n",
      " ('appears', 3),\n",
      " ('sure', 3),\n",
      " ('regular', 2),\n",
      " ('simple', 2),\n",
      " ('superior', 2),\n",
      " ('tactile', 2),\n",
      " ('real', 2),\n",
      " ('portable', 2),\n",
      " ('recommend', 2),\n",
      " ('buy', 2),\n",
      " ('photo', 2),\n",
      " ('complicated', 2),\n",
      " ('sharp', 2),\n",
      " ('decent', 2),\n",
      " ('solid', 2),\n",
      " ('going', 2),\n",
      " ('minor', 2),\n",
      " ('worked', 2),\n",
      " ('absolute', 2),\n",
      " ('favorite', 2),\n",
      " ('does', 2),\n",
      " ('lock', 2),\n",
      " ('additional', 2),\n",
      " ('one', 2),\n",
      " ('goes', 2),\n",
      " ('recorded', 2),\n",
      " ('elaborate', 2),\n",
      " ('biggest', 2),\n",
      " ('ridiculous', 2),\n",
      " ('second', 2),\n",
      " ('whole', 2),\n",
      " ('comes', 2),\n",
      " ('compact', 2),\n",
      " ('central', 2),\n",
      " ('areas', 2),\n",
      " ('recent', 2),\n",
      " ('bright', 2),\n",
      " ('amateur', 2),\n",
      " ('quality', 2),\n",
      " ('close', 2),\n",
      " ('spare', 2),\n",
      " ('pleased', 2),\n",
      " ('improve', 2),\n",
      " ('relative', 2),\n",
      " ('projected', 2),\n",
      " ('newest', 2),\n",
      " ('lasts', 2),\n",
      " ('runs', 2),\n",
      " ('white', 2),\n",
      " ('helpful', 2),\n",
      " ('affordable', 2),\n",
      " ('due', 2),\n",
      " ('wider', 2),\n",
      " ('cheap', 2),\n",
      " ('takes', 2),\n",
      " ('purple', 2),\n",
      " ('practical', 2),\n",
      " ('happy', 2),\n",
      " ('heavy', 2),\n",
      " ('about', 2),\n",
      " ('basic', 2),\n",
      " ('got', 2),\n",
      " ('personal', 2),\n",
      " ('years', 1),\n",
      " ('shoots', 1),\n",
      " ('beats', 1),\n",
      " ('ways', 1),\n",
      " ('increases', 1),\n",
      " ('rechargeable', 1),\n",
      " ('fluctuates', 1),\n",
      " ('charge', 1),\n",
      " ('beautiful', 1),\n",
      " ('run', 1),\n",
      " ('cheapest', 1),\n",
      " ('held', 1),\n",
      " ('ago', 1),\n",
      " ('user', 1),\n",
      " ('supposed', 1),\n",
      " ('common', 1),\n",
      " ('needs', 1),\n",
      " ('writing', 1),\n",
      " ('jumpy', 1),\n",
      " ('test', 1),\n",
      " ('number', 1),\n",
      " ('unsatisfied', 1),\n",
      " ('arrived', 1),\n",
      " ('change', 1),\n",
      " ('stinks', 1),\n",
      " ('super', 1),\n",
      " ('figured', 1),\n",
      " ('newer', 1),\n",
      " ('larger', 1),\n",
      " ('funny', 1),\n",
      " ('following', 1),\n",
      " ('spacious', 1),\n",
      " ('capacitive', 1),\n",
      " ('recognize', 1),\n",
      " ('confused', 1),\n",
      " ('ready', 1),\n",
      " ('accurate', 1),\n",
      " ('hollow', 1),\n",
      " ('intuitive', 1),\n",
      " ('boils', 1),\n",
      " ('finished', 1),\n",
      " ('major', 1),\n",
      " ('mega', 1),\n",
      " ('different', 1),\n",
      " ('feature', 1),\n",
      " ('umpteenth', 1),\n",
      " ('neat', 1),\n",
      " ('shakes', 1),\n",
      " ('magic', 1),\n",
      " ('bundled', 1),\n",
      " ('buttons', 1),\n",
      " ('accumulate', 1),\n",
      " ('update', 1),\n",
      " ('inclined', 1),\n",
      " ('accepts', 1),\n",
      " ('registered', 1),\n",
      " ('serial', 1),\n",
      " ('indicated', 1),\n",
      " ('flip', 1),\n",
      " ('bought', 1),\n",
      " ('free', 1),\n",
      " ('microphone', 1),\n",
      " ('exceptional', 1),\n",
      " ('aspiring', 1),\n",
      " ('expired', 1),\n",
      " ('emailed', 1),\n",
      " ('sized', 1),\n",
      " ('playing', 1),\n",
      " ('else', 1),\n",
      " ('occur', 1),\n",
      " ('option', 1),\n",
      " ('broke', 1),\n",
      " ('addition', 1),\n",
      " ('worst', 1),\n",
      " ('button', 1),\n",
      " ('actual', 1),\n",
      " ('wonderful', 1),\n",
      " ('glossy', 1),\n",
      " ('stunning', 1),\n",
      " ('needed', 1),\n",
      " ('lower', 1),\n",
      " ('added', 1),\n",
      " ('surprise', 1),\n",
      " ('way', 1),\n",
      " ('varies', 1),\n",
      " ('selling', 1),\n",
      " ('videoweighs', 1),\n",
      " ('intuitivethe', 1),\n",
      " ('local', 1),\n",
      " ('love', 1),\n",
      " ('cameras', 1),\n",
      " ('difficult', 1),\n",
      " ('mentioned', 1),\n",
      " ('ought', 1),\n",
      " ('upper', 1),\n",
      " ('flush', 1),\n",
      " ('size', 1),\n",
      " ('intrusive', 1),\n",
      " ('troubleshooting', 1),\n",
      " ('correct', 1),\n",
      " ('stayed', 1),\n",
      " ('terrible', 1),\n",
      " ('main', 1),\n",
      " ('teenage', 1),\n",
      " ('overall', 1),\n",
      " ('died', 1),\n",
      " ('fails', 1),\n",
      " ('waste', 1),\n",
      " ('online', 1),\n",
      " ('help', 1),\n",
      " ('lit', 1),\n",
      " ('stay', 1),\n",
      " ('proper', 1),\n",
      " ('convinced', 1),\n",
      " ('bulky', 1),\n",
      " ('outstanding', 1),\n",
      " ('functions', 1),\n",
      " ('hold', 1),\n",
      " ('makes', 1),\n",
      " ('installed', 1),\n",
      " ('prompted', 1),\n",
      " ('do', 1),\n",
      " ('sunlight', 1),\n",
      " ('effective', 1),\n",
      " ('picture', 1),\n",
      " ('deliver', 1),\n",
      " ('sub', 1),\n",
      " ('provide', 1),\n",
      " ('need', 1),\n",
      " ('sony', 1),\n",
      " ('back', 1),\n",
      " ('arm', 1),\n",
      " ('rubber', 1),\n",
      " ('flexible', 1),\n",
      " ('awkward', 1),\n",
      " ('worried', 1),\n",
      " ('outlived', 1),\n",
      " ('horizontal', 1),\n",
      " ('smudged', 1),\n",
      " ('puts', 1),\n",
      " ('sucks', 1),\n",
      " ('such', 1),\n",
      " ('types', 1),\n",
      " ('say', 1),\n",
      " ('alternate', 1),\n",
      " ('replaceable', 1),\n",
      " ('rare', 1),\n",
      " ('operating', 1),\n",
      " ('enough', 1),\n",
      " ('latest', 1),\n",
      " ('lowest', 1),\n",
      " ('accommodate', 1),\n",
      " ('think', 1),\n",
      " ('unlimited', 1),\n",
      " ('obvious', 1),\n",
      " ('highest', 1),\n",
      " ('possible', 1),\n",
      " ('drive', 1),\n",
      " ('settled', 1),\n",
      " ('middle', 1),\n",
      " ('produces', 1),\n",
      " ('astounded', 1),\n",
      " ('highly', 1),\n",
      " ('four', 1),\n",
      " ('charged', 1),\n",
      " ('netbook', 1),\n",
      " ('much', 1),\n",
      " ('amazing', 1),\n",
      " ('factor', 1),\n",
      " ('important', 1),\n",
      " ('inclement', 1),\n",
      " ('appropriate', 1),\n",
      " ('suitable', 1),\n",
      " ('remains', 1),\n",
      " ('reasonable', 1),\n",
      " ('firm', 1),\n",
      " ('sensitivity', 1),\n",
      " ('over', 1),\n",
      " ('prone', 1),\n",
      " ('accompanying', 1),\n",
      " ('informative', 1),\n",
      " ('coolest', 1),\n",
      " ('learned', 1),\n",
      " ('anti', 1),\n",
      " ('unintuitive', 1),\n",
      " ('designed', 1),\n",
      " ('year', 1),\n",
      " ('customary', 1),\n",
      " ('did', 1),\n",
      " ('worth', 1),\n",
      " ('technical', 1),\n",
      " ('genius', 1),\n",
      " ('awful', 1),\n",
      " ('go', 1),\n",
      " ('withstand', 1),\n",
      " ('shooting', 1),\n",
      " ('third', 1),\n",
      " ('allowed', 1),\n",
      " ('agreat', 1),\n",
      " ('slim', 1),\n",
      " ('pops', 1),\n",
      " ('soft', 1),\n",
      " ('able', 1),\n",
      " ('windy', 1),\n",
      " ('outside', 1),\n",
      " ('picked', 1),\n",
      " ('sweet', 1),\n",
      " ('current', 1),\n",
      " ('take', 1),\n",
      " ('fledged', 1),\n",
      " ('choppy', 1),\n",
      " ('complete', 1),\n",
      " ('beat', 1),\n",
      " ('wrong', 1),\n",
      " ('dismayed', 1),\n",
      " ('me', 1),\n",
      " ('suggested', 1),\n",
      " ('underwater', 1),\n",
      " ('tooo', 1),\n",
      " ('use', 1),\n",
      " ('identical', 1),\n",
      " ('inches', 1),\n",
      " ('charging', 1),\n",
      " ('clean', 1),\n",
      " ('left', 1),\n",
      " ('slight', 1),\n",
      " ('brighter', 1),\n",
      " ('physical', 1),\n",
      " ('promotional', 1),\n",
      " ('point', 1),\n",
      " ('make', 1),\n",
      " ('plenty', 1),\n",
      " ('lens', 1),\n",
      " ('narrow', 1),\n",
      " ('red', 1),\n",
      " ('pointed', 1),\n",
      " ('turns', 1),\n",
      " ('indicates', 1),\n",
      " ('pale', 1),\n",
      " ('yellow', 1),\n",
      " ('faded', 1),\n",
      " ('ruby', 1),\n",
      " ('brilliant', 1),\n",
      " ('dark', 1),\n",
      " ('normal', 1),\n",
      " ('gimmick', 1),\n",
      " ('stupid', 1),\n",
      " ('eats', 1),\n",
      " ('chew', 1),\n",
      " ('allow', 1),\n",
      " ('timely', 1),\n",
      " ('look', 1),\n",
      " ('previous', 1),\n",
      " ('outdated', 1),\n",
      " ('desktop', 1),\n",
      " ('match', 1),\n",
      " ('comparable', 1),\n",
      " ('there', 1),\n",
      " ('record', 1),\n",
      " ('elemental', 1),\n",
      " ('sick', 1),\n",
      " ('tired', 1),\n",
      " ('earlier', 1),\n",
      " ('suck', 1),\n",
      " ('secondary', 1),\n",
      " ('suffers', 1),\n",
      " ('ability', 1),\n",
      " ('wireless', 1),\n",
      " ('intended', 1),\n",
      " ('substantial', 1),\n",
      " ('versatile', 1),\n",
      " ('live', 1),\n",
      " ('loud', 1),\n",
      " ('prolonged', 1),\n",
      " ('shiny', 1),\n",
      " ('smudgeable', 1),\n",
      " ('complains', 1),\n",
      " ('special', 1),\n",
      " ('painless', 1),\n",
      " ('integrates', 1),\n",
      " ('easier', 1),\n",
      " ('version', 1),\n",
      " ('rubbery', 1),\n",
      " ('mounts', 1),\n",
      " ('weight', 1),\n",
      " ('preferred', 1),\n",
      " ('prominent', 1),\n",
      " ('smooth', 1),\n",
      " ('automatic', 1),\n",
      " ('blue', 1),\n",
      " ('try', 1),\n",
      " ('long', 1),\n",
      " ('blew', 1),\n",
      " ('surpasses', 1),\n",
      " ('handheld', 1),\n",
      " ('encouraged', 1),\n",
      " ('useless', 1),\n",
      " ('supports', 1),\n",
      " ('camcorder', 1),\n",
      " ('hemorrhaging', 1),\n",
      " ('exited', 1),\n",
      " ('asked', 1),\n",
      " ('knows', 1),\n",
      " ('biting', 1),\n",
      " ('brief', 1),\n",
      " ('forgiving', 1),\n",
      " ('broad', 1),\n",
      " ('multifunction', 1),\n",
      " ('standard', 1),\n",
      " ('mounting', 1),\n",
      " ('flimsyindependent', 1),\n",
      " ('means', 1),\n",
      " ('extrarounded', 1),\n",
      " ('own', 1),\n",
      " ('manual', 1),\n",
      " ('impressive', 1),\n",
      " ('working', 1),\n",
      " ('competent', 1),\n",
      " ('dirty', 1),\n",
      " ('boasted', 1),\n",
      " ('complex', 1),\n",
      " ('bigger', 1),\n",
      " ('true', 1),\n",
      " ('comparative', 1),\n",
      " ('persnickety', 1),\n",
      " ('audiovisual', 1),\n",
      " ('advanced', 1),\n",
      " ('positive', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Opinion words, occurrences:\")\n",
    "opinions_by_count = sorted(opinions_count.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(opinions_by_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def is_sentiment_bearing(adj):\n",
    "    for ss in wn.synsets(adj):\n",
    "        if ss.pos() == \"a\" or ss.pos() == \"s\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT FOUND: {'turn', 'record', 'gimmick', 'camcorder', 'point', 'flimsyindependent', 'option', 'mounting', 'boasted', 'video', 'charging', 'genius', 'stayed', 'supports', 'need', 'suggested', 'did', 'tooo', 'increases', 'beats', 'match', 'functions', 'arm', 'suffers', 'improve', 'sensitivity', 'was', 'added', 'is', 'highly', 'microphone', 'turns', 'test', 'playing', 'update', 'puts', 'unintuitive', 'makes', 'means', 'factor', 'surpasses', 'hold', 'sunlight', 'sucks', 'recording', 'stay', 'try', 'eats', 'sub', 'addition', 'help', 'accommodate', 'suck', 'needs', 'way', 'varies', 'cameras', 'power', 'shooting', 'writing', 'videoweighs', 'exited', 'mega', 'work', 'died', 'has', 'indicates', 'fails', 'smudgeable', 'shoots', 'integrates', 'picked', 'emailed', 'feature', 'intuitivethe', 'takes', 'accepts', 'produces', 'arrived', 'fluctuates', 'do', 'asked', 'user', 'weight', 'drive', 'inches', 'occur', 'boils', 'lasts', 'remains', 'comes', 'me', 'extrarounded', 'areas', 'version', 'say', 'runs', 'recommend', 'allowed', 'does', 'use', 'love', 'picture', 'bought', 'agreat', 'worked', 'works', 'smudged', 'allow', 'lens', 'recognize', 'withstand', 'selling', 'ability', 'prompted', 'buttons', 'make', 'charge', 'year', 'blew', 'mic', 'usb', 'have', 'sony', 'knows', 'audio', 'outlived', 'pops', 'change', 'provide', 'mentioned', 'multifunction', 'buy', 'plenty', 'goes', 'indicated', 'surprise', 'types', 'complains', 'number', 'shakes', 'photo', 'ways', 'there', 'years', 'button', 'desktop', 'seems', 'lock', 'stinks', 'ought', 'deliver', 'else', 'look', 'appears', 'bundled', 'hemorrhaging', 'installed', 'got', 'run', 'think', 'troubleshooting', 'mounts', 'netbook', 'chew', 'take', 'accumulate'}\n",
      "FOUND: {'astounded', 'larger', 'four', 'close', 'next', 'middle', 'spare', 'neat', 'outstanding', 'sized', 'rubber', 'central', 'highest', 'live', 'registered', 'local', 'bigger', 'dedicated', 'accurate', 'overall', 'professional', 'actual', 'teenage', 'learned', 'favorite', 'much', 'acceptable', 'exceptional', 'first', 'firm', 'sound', 'included', 'designed', 'solid', 'narrow', 'surprised', 'secondary', 'second', 'compact', 'prone', 'happy', 'suitable', 'other', 'better', 'wireless', 'preferred', 'awkward', 'crisp', 'basic', 'special', 'intuitive', 'lower', 'sweet', 'ridiculous', 'substantial', 'big', 'simple', 'operating', 'smooth', 'standard', 'super', 'best', 'fledged', 'magic', 'technical', 'yellow', 'aspiring', 'effective', 'pale', 'faded', 'ruby', 'choppy', 'prolonged', 'old', 'portable', 'handheld', 'bright', 'white', 'similar', 'fantastic', 'funny', 'major', 'blue', 'impressive', 'enough', 'practical', 'creative', 'about', 'free', 'unlimited', 'normal', 'regular', 'advanced', 'great', 'flexible', 'elemental', 'flush', 'quick', 'rare', 'worried', 'handy', 'online', 'needed', 'lightweight', 'amateur', 'brighter', 'promotional', 'rubbery', 'biggest', 'external', 'correct', 'competent', 'versatile', 'perfect', 'lowest', 'complicated', 'affordable', 'tactile', 'audiovisual', 'go', 'third', 'awful', 'broke', 'pointed', 'positive', 'new', 'sure', 'decent', 'relative', 'different', 'stupid', 'flip', 'important', 'following', 'brilliant', 'light', 'fine', 'ready', 'proper', 'complete', 'easier', 'excellent', 'bad', 'comparative', 'recent', 'poor', 'informative', 'additional', 'prominent', 'easy', 'real', 'hollow', 'little', 'back', 'outside', 'left', 'hard', 'useless', 'superior', 'persnickety', 'bulky', 'replaceable', 'manual', 'charged', 'amazing', 'nice', 'wonderful', 'purple', 'forgiving', 'broad', 'main', 'painless', 'jumpy', 'pleased', 'cheap', 'able', 'waste', 'sick', 'stunning', 'same', 'possible', 'inexpensive', 'own', 'available', 'absolute', 'difficult', 'last', 'inclined', 'sharp', 'latest', 'shiny', 'huge', 'awesome', 'upper', 'heavy', 'settled', 'over', 'dark', 'tired', 'timely', 'such', 'slim', 'internal', 'intrusive', 'only', 'current', 'impressed', 'helpful', 'confused', 'defective', 'common', 'newest', 'reasonable', 'going', 'entire', 'expired', 'worth', 'worst', 'earlier', 'convinced', 'anti', 'identical', 'ago', 'wider', 'figured', 'windy', 'coolest', 'minor', 'biting', 'true', 'soft', 'dismayed', 'held', 'appropriate', 'previous', 'intended', 'superb', 'complex', 'horizontal', 'removable', 'physical', 'wrong', 'comparable', 'finished', 'good', 'recorded', 'dirty', 'projected', 'accompanying', 'encouraged', 'inclement', 'quality', 'personal', 'beat', 'high', 'slight', 'automatic', 'small', 'plus', 'digital', 'clear', 'lit', 'alternate', 'outdated', 'one', 'terrible', 'brief', 'whole', 'red', 'capacitive', 'wide', 'sensitive', 'tiny', 'beautiful', 'clean', 'working', 'long', 'elaborate', 'extra', 'size', 'short', 'more', 'unsatisfied', 'serial', 'spacious', 'newer', 'umpteenth', 'due', 'right', 'supposed', 'glossy', 'cheapest', 'customary', 'loud', 'cool', 'full', 'higher', 'underwater', 'obvious', 'rechargeable', 'low'}\n"
     ]
    }
   ],
   "source": [
    "found = set()\n",
    "not_found = set()\n",
    "\n",
    "for opinion, _ in opinions_by_count:\n",
    "    if is_sentiment_bearing(opinion):\n",
    "        found.add(opinion)\n",
    "    else:\n",
    "        not_found.add(opinion)\n",
    "    \n",
    "print(\"NOT FOUND: \" + str(not_found))\n",
    "print(\"FOUND: \" + str(found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Feature cumulative sentiments:\")\n",
    "feature_sentiments_cumulative_sorted = sorted(feature_sentiments_cumulative.items(), key=lambda x: x[1], reverse=True)\n",
    "feature_sentiments_cumulative_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion word sentiments:\n",
      "[('horrible', -1),\n",
      " ('poor', -1),\n",
      " ('miserable', -1),\n",
      " ('unreliable', -1),\n",
      " ('complicated', -1),\n",
      " ('annoying', -1),\n",
      " ('worst', -1),\n",
      " ('defective', -1),\n",
      " ('weak', -1),\n",
      " ('lousy', -1),\n",
      " ('difficult', -1),\n",
      " ('sloppy', -1),\n",
      " ('malfunctioning', -1),\n",
      " ('useless', -1),\n",
      " ('mediocre', -1),\n",
      " ('unstable', -1),\n",
      " ('inferior', -1),\n",
      " ('old', -1),\n",
      " ('buggy', -1),\n",
      " ('weird', -1),\n",
      " ('bad', -1),\n",
      " ('terrible', -1),\n",
      " ('strange', -1),\n",
      " ('misleading', -1),\n",
      " ('narrow', -1),\n",
      " ('okay', -1),\n",
      " ('superb', -1),\n",
      " ('turns', -1),\n",
      " ('higher', -1),\n",
      " ('lot', -1),\n",
      " ('unusable', -1),\n",
      " ('intense', -1),\n",
      " ('facing', -1),\n",
      " ('general', -1),\n",
      " ('allowing', -1),\n",
      " ('different', 0),\n",
      " ('polarizing', 0),\n",
      " ('renowned', 0),\n",
      " ('decent', 0),\n",
      " ('original', 0),\n",
      " ('much', 0),\n",
      " ('fine', 0),\n",
      " ('competitive', 0),\n",
      " ('loose', 0),\n",
      " ('third', 0),\n",
      " ('circular', 0),\n",
      " ('rotating', 0),\n",
      " ('come', 0),\n",
      " ('useful', 0),\n",
      " ('continued', 0),\n",
      " ('deep', 0),\n",
      " ('minimalist', 0),\n",
      " ('west', 0),\n",
      " ('cheaper', 0),\n",
      " ('affordable', 0),\n",
      " ('reasonable', 0),\n",
      " ('helps', 0),\n",
      " ('appears', 0),\n",
      " ('incoming', 0),\n",
      " ('everyday', 0),\n",
      " ('included', 0),\n",
      " ('ambient', 0),\n",
      " ('ultrawide', 0),\n",
      " ('reliable', 0),\n",
      " ('equivalent', 0),\n",
      " ('exception', 0),\n",
      " ('wasnt', 0),\n",
      " ('big', 0),\n",
      " ('arrived', 0),\n",
      " ('optimum', 0),\n",
      " ('build', 0),\n",
      " ('atmospheric', 0),\n",
      " ('essential', 0),\n",
      " ('beautiful', 0),\n",
      " ('poloarized', 0),\n",
      " ('too', 0),\n",
      " ('recommended', 0),\n",
      " ('harsh', 0),\n",
      " ('goes', 0),\n",
      " ('had', 0),\n",
      " ('bluer', 0),\n",
      " ('degrades', 0),\n",
      " ('bought', 0),\n",
      " ('fall', 0),\n",
      " ('main', 0),\n",
      " ('detailed', 0),\n",
      " ('more', 0),\n",
      " ('close', 0),\n",
      " ('top', 0),\n",
      " ('functions', 0),\n",
      " ('saturates', 0),\n",
      " ('earliest', 0),\n",
      " ('job', 0),\n",
      " ('damaging', 0),\n",
      " ('there', 0),\n",
      " ('versatile', 0),\n",
      " ('untouched', 0),\n",
      " ('hard', 0),\n",
      " ('made', 0),\n",
      " ('cirucular', 0),\n",
      " ('little', 0),\n",
      " ('accomplishes', 0),\n",
      " ('thick', 0),\n",
      " ('richer', 0),\n",
      " ('professional', 0),\n",
      " ('have', 0),\n",
      " ('additional', 0),\n",
      " ('simultaneous', 0),\n",
      " ('sealed', 0),\n",
      " ('high', 0),\n",
      " ('extra', 0),\n",
      " ('enhances', 0),\n",
      " ('worked', 0),\n",
      " ('prevents', 0),\n",
      " ('lint', 0),\n",
      " ('crafted', 0),\n",
      " ('outrageous', 0),\n",
      " ('whole', 0),\n",
      " ('go', 0),\n",
      " ('optical', 0),\n",
      " ('estimated', 0),\n",
      " ('incredible', 0),\n",
      " ('similar', 0),\n",
      " ('plain', 0),\n",
      " ('came', 0),\n",
      " ('huge', 0),\n",
      " ('visible', 0),\n",
      " ('costs', 0),\n",
      " ('darkens', 0),\n",
      " ('work', 0),\n",
      " ('mexican', 0),\n",
      " ('longest', 0),\n",
      " ('correct', 0),\n",
      " ('multiuse', 0),\n",
      " ('rattle', 0),\n",
      " ('coated', 0),\n",
      " ('smaller', 0),\n",
      " ('help', 0),\n",
      " ('clockwise', 0),\n",
      " ('spins', 0),\n",
      " ('enough', 0),\n",
      " ('cool', 0),\n",
      " ('visual', 0),\n",
      " ('gives', 0),\n",
      " ('used', 0),\n",
      " ('brightest', 0),\n",
      " ('wash', 0),\n",
      " ('pronounced', 0),\n",
      " ('yellow', 0),\n",
      " ('existing', 0),\n",
      " ('round', 0),\n",
      " ('saved', 0),\n",
      " ('lower', 0),\n",
      " ('cloudless', 0),\n",
      " ('depth', 0),\n",
      " ('plastic', 0),\n",
      " ('do', 0),\n",
      " ('tollerable', 0),\n",
      " ('noticed', 0),\n",
      " ('average', 0),\n",
      " ('attractive', 0),\n",
      " ('powerful', 0),\n",
      " ('photographic', 0),\n",
      " ('off', 0),\n",
      " ('see', 0),\n",
      " ('variable', 0),\n",
      " ('careful', 0),\n",
      " ('getting', 0),\n",
      " ('nad', 0),\n",
      " ('surround', 0),\n",
      " ('worth', 0),\n",
      " ('ok', 0),\n",
      " ('unsealed', 0),\n",
      " ('rotate', 0),\n",
      " ('real', 0),\n",
      " ('seem', 0),\n",
      " ('intact', 0),\n",
      " ('popular', 0),\n",
      " ('stick', 0),\n",
      " ('extreme', 0),\n",
      " ('confident', 0),\n",
      " ('alive', 0),\n",
      " ('relative', 0),\n",
      " ('snaps', 0),\n",
      " ('small', 0),\n",
      " ('adjusting', 0),\n",
      " ('coming', 0),\n",
      " ('vivid', 0),\n",
      " ('important', 0),\n",
      " ('extend', 0),\n",
      " ('set', 0),\n",
      " ('light', 0),\n",
      " ('unwanted', 0),\n",
      " ('mindful', 0),\n",
      " ('quick', 0),\n",
      " ('thicker', 0),\n",
      " ('comes', 0),\n",
      " ('was', 0),\n",
      " ('fair', 0),\n",
      " ('else', 0),\n",
      " ('longtime', 0),\n",
      " ('recent', 0),\n",
      " ('scenic', 0),\n",
      " ('open', 0),\n",
      " ('factor', 0),\n",
      " ('major', 0),\n",
      " ('making', 0),\n",
      " ('tiffen', 0),\n",
      " ('rectangular', 0),\n",
      " ('cheapo', 0),\n",
      " ('black', 0),\n",
      " ('due', 0),\n",
      " ('hairy', 0),\n",
      " ('shooting', 0),\n",
      " ('try', 0),\n",
      " ('polarizes', 0),\n",
      " ('practical', 0),\n",
      " ('fat', 0),\n",
      " ('mirrorless', 0),\n",
      " ('sole', 0),\n",
      " ('older', 0),\n",
      " ('closed', 0),\n",
      " ('micro', 0),\n",
      " ('free', 0),\n",
      " ('super', 1),\n",
      " ('good', 1),\n",
      " ('realistic', 1),\n",
      " ('precise', 1),\n",
      " ('impressive', 1),\n",
      " ('solid', 1),\n",
      " ('great', 1),\n",
      " ('comfortable', 1),\n",
      " ('friendly', 1),\n",
      " ('vibrant', 1),\n",
      " ('perfect', 1),\n",
      " ('better', 1),\n",
      " ('bright', 1),\n",
      " ('clear', 1),\n",
      " ('strong', 1),\n",
      " ('stunning', 1),\n",
      " ('amazing', 1),\n",
      " ('exceptional', 1),\n",
      " ('simple', 1),\n",
      " ('awesome', 1),\n",
      " ('rich', 1),\n",
      " ('superior', 1),\n",
      " ('easy', 1),\n",
      " ('excellent', 1),\n",
      " ('fantastic', 1),\n",
      " ('nice', 1),\n",
      " ('ideal', 1),\n",
      " ('best', 1),\n",
      " ('right', 1),\n",
      " ('saturated', 1),\n",
      " ('clean', 1),\n",
      " ('heavy', 1),\n",
      " ('sure', 1),\n",
      " ('inexpensive', 1),\n",
      " ('cheap', 1),\n",
      " ('sharp', 1),\n",
      " ('smooth', 1),\n",
      " ('effective', 1),\n",
      " ('honest', 1),\n",
      " ('remarkable', 1),\n",
      " ('what', 1),\n",
      " ('straight', 1),\n",
      " ('other', 1),\n",
      " ('covers', 1),\n",
      " ('items', 1),\n",
      " ('adhesive', 1),\n",
      " ('inside', 1),\n",
      " ('overall', 1),\n",
      " ('same', 1),\n",
      " ('becomes', 1),\n",
      " ('thinner', 1),\n",
      " ('wrong', 1),\n",
      " ('darken', 1),\n",
      " ('nicer', 1),\n",
      " ('subtle', 1),\n",
      " ('many', 1),\n",
      " ('does', 1),\n",
      " ('died', 1),\n",
      " ('gone', 1),\n",
      " ('seems', 1),\n",
      " ('only', 1),\n",
      " ('focus', 1),\n",
      " ('improved', 1),\n",
      " ('threaded', 1),\n",
      " ('has', 1),\n",
      " ('occasional', 1),\n",
      " ('digital', 1),\n",
      " ('is', 1),\n",
      " ('need', 1),\n",
      " ('long', 1),\n",
      " ('particular', 1),\n",
      " ('filter', 1),\n",
      " ('new', 1),\n",
      " ('linear', 1),\n",
      " ('either', 1),\n",
      " ('single', 1),\n",
      " ('sunny', 1),\n",
      " ('look', 1),\n",
      " ('most', 1),\n",
      " ('past', 1),\n",
      " ('first', 1),\n",
      " ('snug', 1),\n",
      " ('sufficient', 1),\n",
      " ('works', 1),\n",
      " ('valuable', 1),\n",
      " ('ancient', 1),\n",
      " ('own', 1),\n",
      " ('make', 1),\n",
      " ('blah', 1),\n",
      " ('turning', 1),\n",
      " ('wonderful', 1),\n",
      " ('fits', 1),\n",
      " ('done', 1),\n",
      " ('turn', 1),\n",
      " ('expensive', 1),\n",
      " ('fit', 1),\n",
      " ('give', 1),\n",
      " ('blue', 1),\n",
      " ('dark', 1),\n",
      " ('missing', 1),\n",
      " ('crisper', 1),\n",
      " ('enhanced', 1),\n",
      " ('makes', 1),\n",
      " ('priced', 1),\n",
      " ('fx', 1),\n",
      " ('direct', 1),\n",
      " ('noticeable', 1),\n",
      " ('knurled', 1),\n",
      " ('expected', 1),\n",
      " ('polarized', 1),\n",
      " ('larger', 1),\n",
      " ('near', 1),\n",
      " ('outdoor', 1),\n",
      " ('nikon', 1),\n",
      " ('feels', 1),\n",
      " ('last', 1),\n",
      " ('significant', 1),\n",
      " ('wide', 1),\n",
      " ('thin', 1),\n",
      " ('extensive', 1),\n",
      " ('unscrew', 1),\n",
      " ('low', 1),\n",
      " ('next', 1),\n",
      " ('flourescent', 1),\n",
      " ('raw', 1),\n",
      " ('punch', 1),\n",
      " ('full', 1),\n",
      " ('focuses', 1),\n",
      " ('hazy', 1),\n",
      " ('sturdy', 1),\n",
      " ('christmas', 1),\n",
      " ('outside', 1),\n",
      " ('fell', 1),\n",
      " ('minimal', 1),\n",
      " ('less', 1),\n",
      " ('deeper', 1),\n",
      " ('moving', 1),\n",
      " ('flawless', 1),\n",
      " ('acceptable', 1),\n",
      " ('durable', 1),\n",
      " ('product', 1),\n",
      " ('proper', 1),\n",
      " ('prime', 1),\n",
      " ('bit', 1),\n",
      " ('reduce', 1),\n",
      " ('pleasing', 1),\n",
      " ('brilliant', 1),\n",
      " ('quality', 1),\n",
      " ('traditional', 1),\n",
      " ('protective', 1),\n",
      " ('went', 1),\n",
      " ('cloudy', 1),\n",
      " ('pricey', 1),\n",
      " ('landscapes', 1),\n",
      " ('neutral', 1),\n",
      " ('excelent', 1),\n",
      " ('warming', 1),\n",
      " ('internal', 1),\n",
      " ('dirty', 1),\n",
      " ('tight', 1),\n",
      " ('fast', 1),\n",
      " ('size', 1),\n",
      " ('tough', 1),\n",
      " ('natural', 1),\n",
      " ('amateur', 1),\n",
      " ('reflected', 1),\n",
      " ('dramatic', 1),\n",
      " ('admirably', 1),\n",
      " ('addition', 1),\n",
      " ('takes', 1),\n",
      " ('happy', 1),\n",
      " ('stronger', 1),\n",
      " ('pro', 1),\n",
      " ('corrects', 1),\n",
      " ('possible', 1),\n",
      " ('necessary', 1),\n",
      " ('chamber', 1),\n",
      " ('lens', 1),\n",
      " ('second', 1),\n",
      " ('easiest', 1),\n",
      " ('spin', 1),\n",
      " ('satisfactory', 1),\n",
      " ('deal', 1),\n",
      " ('regular', 1),\n",
      " ('determines', 1),\n",
      " ('looks', 1),\n",
      " ('unharmed', 1),\n",
      " ('several', 1),\n",
      " ('popped', 1),\n",
      " ('basic', 1),\n",
      " ('produces', 1),\n",
      " ('ihave', 1),\n",
      " ('broad', 1),\n",
      " ('fun', 1),\n",
      " ('exposed', 1),\n",
      " ('typical', 1),\n",
      " ('beats', 1),\n",
      " ('compromise', 1),\n",
      " ('unnatural', 1),\n",
      " ('profound', 1),\n",
      " ('widest', 1),\n",
      " ('merciful', 1),\n",
      " ('mounted', 1),\n",
      " ('standard', 1),\n",
      " ('stellar', 1),\n",
      " ('indoor', 1),\n",
      " ('working', 1),\n",
      " ('take', 1),\n",
      " ('darker', 1),\n",
      " ('rough', 1),\n",
      " ('previous', 1),\n",
      " ('uncoated', 1),\n",
      " ('hits', 1),\n",
      " ('whitish', 1),\n",
      " ('minded', 1),\n",
      " ('opposite', 1),\n",
      " ('disappear', 1),\n",
      " ('green', 1),\n",
      " ('blessing', 1),\n",
      " ('positive', 1),\n",
      " ('temporary', 1),\n",
      " ('locking', 1),\n",
      " ('outer', 1),\n",
      " ('hanging', 1),\n",
      " ('excessive', 1),\n",
      " ('safe', 1),\n",
      " ('shows', 1),\n",
      " ('buttery', 1),\n",
      " ('actual', 1),\n",
      " ('sweet', 1),\n",
      " ('solar', 1),\n",
      " ('primary', 1),\n",
      " ('carry', 1),\n",
      " ('warm', 1),\n",
      " ('greasy', 1),\n",
      " ('mounting', 1),\n",
      " ('key', 1),\n",
      " ('unnecessary', 1),\n",
      " ('stay', 1),\n",
      " ('bottom', 1),\n",
      " ('going', 1),\n",
      " ('shakes', 1),\n",
      " ('ugly', 1),\n",
      " ('horrendous', 1),\n",
      " ('manual', 1),\n",
      " ('looked', 1),\n",
      " ('happened', 1),\n",
      " ('packaging', 1),\n",
      " ('cubic', 1),\n",
      " ('item', 1),\n",
      " ('forested', 1),\n",
      " ('front', 1),\n",
      " ('biggest', 1),\n",
      " ('balanced', 1),\n",
      " ('reason', 1),\n",
      " ('definite', 1),\n",
      " ('intercostal', 1),\n",
      " ('rotates', 1),\n",
      " ('one', 1),\n",
      " ('phenomenal', 1),\n",
      " ('further', 1),\n",
      " ('minor', 1),\n",
      " ('bigger', 1),\n",
      " ('automatic', 1),\n",
      " ('know', 1),\n",
      " ('timely', 1),\n",
      " ('buy', 1),\n",
      " ('can', 1),\n",
      " ('eliminate', 1),\n",
      " ('told', 1),\n",
      " ('asset', 1),\n",
      " ('slight', 1),\n",
      " ('fisheye', 1),\n",
      " ('oversized', 1),\n",
      " ('unsmooth', 1),\n",
      " ('commercial', 1),\n",
      " ('advanced', 1),\n",
      " ('bluish', 1),\n",
      " ('added', 1),\n",
      " ('steady', 1),\n",
      " ('thorough', 1),\n",
      " ('nasty', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Opinion word sentiments:\")\n",
    "pprint(sorted(opinion_sentiments.items(), key=lambda x:x[1], reverse=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Newly discovered opinion words:\")\n",
    "pprint(opinions.difference(positive_lexicon.union(negative_lexicon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = {}\n",
    "for i in review_indices:\n",
    "    compiled_results[i] = {}\n",
    "    compiled_results[i]['opinion_words'] = opinion_words_by_review[i]\n",
    "    compiled_results[i]['feature_sentiments'] = feature_sentiments_by_review[i]\n",
    "    \n",
    "pprint(compiled_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews(features, opinions, parsed_sentences, review_indices, raw_sentences, feature_sentiments_by_review):\n",
    "    FO_dict = defaultdict(list)\n",
    "    j = 0\n",
    "    k = -1\n",
    "    for i, sentence in enumerate(parsed_sentences):\n",
    "        phrase_dict = {}\n",
    "        FO_dict_sentence = defaultdict(list)\n",
    "        review_index = review_indices[i]\n",
    "        if review_index != review_indices[i-1]:\n",
    "            j = 0\n",
    "            print(\"==========================================\\n\\nReview #{}\".format(review_index))\n",
    "        else:\n",
    "            j += 1\n",
    "        k += 1\n",
    "        print(\"\\n\\tSentence #{}\".format(j))\n",
    "        print(\"\\t{}\".format(raw_sentences[k]))\n",
    "        for (gov, gov_pos), dependency, (dep, dep_pos) in sentence:\n",
    "            if not gov.isalpha() or not dep.isalpha():\n",
    "                continue\n",
    "            gov = gov.lower()\n",
    "            dep = dep.lower()\n",
    "            if dependency == \"nsubj\" and dep in features:\n",
    "                FO_dict_sentence[dep].append(gov)\n",
    "                print(\"\\t\\tnsubj: {} -> {}, {}\".format(gov, dep, feature_sentiments_by_review[review_index][dep]))\n",
    "            elif dependency == \"amod\" and gov in features:\n",
    "                FO_dict_sentence[gov].append(dep)\n",
    "                print(\"\\t\\tamod: {} -> {}, {}\".format(dep, gov, feature_sentiments_by_review[review_index][gov]))\n",
    "            elif dependency == \"compound\" and gov in features:\n",
    "                phrase_dict[gov] = dep + \" \" + gov\n",
    "        for feature, opinions in FO_dict_sentence.items():\n",
    "            if feature in phrase_dict:\n",
    "                FO_dict[phrase_dict[feature]] += opinions\n",
    "            else:\n",
    "                FO_dict[feature] += opinions\n",
    "    return FO_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews(features,\n",
    "                opinions,\n",
    "                parsed_sentences,\n",
    "                review_indices,\n",
    "                raw_sentences,\n",
    "                feature_sentiments_by_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some notes\n",
    "\n",
    "# still need to handle negations\n",
    "\n",
    "# \"due to the two observations, multiple polarities may be assigned to an opinion word or target\"\n",
    "#   we should keep a running total of observations\n",
    "#   num_negative_sentiments = total_observations - cumulative_polarity\n",
    "\n",
    "# if target is from another review, we use the cumulative polarity to assign sentiment to the opinion word\n",
    "#   should we also assign the cumulative polarity to the target itself?\n",
    "#   we are right now, that way every observed feature gets a sentiment for each occurence\n",
    "\n",
    "# CCB: compute opinion sentiment priors based on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most reviewed asins\n",
    "top_asins = asins[:30]\n",
    "pprint(top_asins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug and play\n",
    "asin_ = \"B003ELYQGG\"\n",
    "\n",
    "reviews_ = get_all_reviews(asin_)\n",
    "\n",
    "features_, \\\n",
    "features_count_, \\\n",
    "opinions_, \\\n",
    "opinions_count_, \\\n",
    "raw_sentences_, \\\n",
    "parsed_sentences_, \\\n",
    "review_indices_, \\\n",
    "feature_sentiments_by_review_, \\\n",
    "feature_words_by_review_, \\\n",
    "feature_sentiments_cumulative_, \\\n",
    "feature_sentiments_pos_, \\\n",
    "feature_sentiments_neg_, \\\n",
    "opinion_words_by_review_, \\\n",
    "opinion_sentiments_ = extract_features_opinions(reviews_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature words, occurrences:\")\n",
    "features_by_count_ = sorted(features_count_.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(features_by_count_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_classes = get_sorted_classes(features_by_count_)\n",
    "pprint(sorted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Opinion words, occurrences:\")\n",
    "opinions_by_count_ = sorted(opinions_count_.items(), key=lambda x:x[1], reverse=True)\n",
    "pprint(opinions_by_count_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature cumulative sentiments:\")\n",
    "feature_sentiments_cumulative_sorted_ = sorted(feature_sentiments_cumulative_.items(), key=lambda x: x[1], reverse=True)\n",
    "feature_sentiments_cumulative_sorted_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Opinion word sentiments:\")\n",
    "pprint(sorted(opinion_sentiments_.items(), key=lambda x:x[1], reverse=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Newly discovered opinion words:\")\n",
    "pprint(opinions_.difference(positive_lexicon.union(negative_lexicon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews(features_,\n",
    "                opinions_,\n",
    "                parsed_sentences_,\n",
    "                review_indices_,\n",
    "                raw_sentences_,\n",
    "                feature_sentiments_by_review_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk processing\n",
    "asins_to_process = asins[:20]\n",
    "product_infos = {}\n",
    "for i, (asin, _) in enumerate(asins_to_process):\n",
    "    try:\n",
    "        print('{}, {}\\n'.format(i, asin))\n",
    "        product_reviews = get_all_reviews(asin)\n",
    "\n",
    "        product_info = {}\n",
    "        product_info['features'], \\\n",
    "        product_info['features_count'], \\\n",
    "        product_info['opinions'], \\\n",
    "        product_info['opinions_count'], \\\n",
    "        product_info['raw_sentences'], \\\n",
    "        product_info['parsed_sentences'], \\\n",
    "        product_info['review_indices'], \\\n",
    "        product_info['feature_sentiments_by_review'], \\\n",
    "        product_info['feature_words_by_review'], \\\n",
    "        product_info['feature_sentiments_cumulative'], \\\n",
    "        product_info['feature_sentiments_pos'], \\\n",
    "        product_info['feature_sentiments_neg'], \\\n",
    "        product_info['opinion_words_by_review'], \\\n",
    "        product_info['opinion_sentiments'] = extract_features_opinions(product_reviews)\n",
    "        \n",
    "        product_infos[asin] = product_info\n",
    "    except ValueError as e:\n",
    "        product_infos[asin] = {'error' : str(e)}\n",
    "        print('Could not process product {} ({})'.format(asin, str(e)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: remove non-english reviews to avoid errors such as \"Invalid control character at: line 1 column 23732 (char 23731)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for asin,product_info in list(product_infos.items())[1:2]:\n",
    "    if 'error' not in product_info:\n",
    "        print('ASIN: {}'.format(asin))\n",
    "        \n",
    "        print('# of Positive Sentiments')\n",
    "        feature_sentiments_pos_sorted = sorted([(k,len(v)) for k,v in product_info['feature_sentiments_pos'].items()], key=lambda x: x[1], reverse=True)\n",
    "        pprint(feature_sentiments_pos_sorted[:15])\n",
    "        \n",
    "        print('# of Negative Sentiments')\n",
    "        feature_sentiments_neg_sorted = sorted([(k,len(v)) for k,v in product_info['feature_sentiments_neg'].items()], key=lambda x: x[1], reverse=True)\n",
    "        pprint(feature_sentiments_neg_sorted[:15])\n",
    "        \n",
    "        feature = feature_sentiments_neg_sorted[0][0]\n",
    "        print('FEATURE: {}'.format(feature))\n",
    "        for review_num, words in product_info['feature_words_by_review'].items():\n",
    "            if feature in words:\n",
    "                if product_info['feature_sentiments_by_review'][review_num][feature] < 0:\n",
    "                    print(review_num, product_info['feature_sentiments_by_review'][review_num][feature])\n",
    "                    for sentence_num,review_num_ in enumerate(product_info['review_indices']):\n",
    "                        if review_num == review_num_:\n",
    "                            sentence = product_info['raw_sentences'][sentence_num]\n",
    "                            if feature in [w.lower() for w in sentence.split()]:\n",
    "                                print(sentence)\n",
    "\n",
    "#                print([product_info['raw_sentences'][sentence_num] \\\n",
    "#                       for sentence_num,review_num in enumerate(product_info['review_indices']) \\\n",
    "#                       if feature in product_info['feature_words_by_review'][review_num] ])                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_infos['B00DR0PDNE']['opinion_words_by_review']\n",
    "pprint([(a,b) for a,b in {k:list(filter(lambda w: (product_infos['B00DR0PDNE']['opinion_sentiments'][w] < 0),v)) for k,v in product_infos['B00DR0PDNE']['opinion_words_by_review'].items()}.items() if len(b)>0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_infos['B00DR0PDNE']['opinion_sentiments']['amazon']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(product_infos['B000LRMS66']['raw_sentences']))\n",
    "print(len(product_infos['B000LRMS66']['feature_words_by_review']))\n",
    "print(product_infos['B000LRMS66']['review_indices'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible statistics\n",
    "# # pos sentiments vs # neg sentiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
